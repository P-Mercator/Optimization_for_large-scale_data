{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Members\n",
    "Pierre Mercatoris – Pablo Bordons Estrada - Sergio Gámez Ruiz de Olano – Mohammadmehdi\n",
    "Fayazbakhsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.28069035]\n",
      " [ 2.12055007]\n",
      " [-3.35364129]\n",
      " [ 2.49180722]\n",
      " [-2.8342821 ]\n",
      " [ 2.01194948]\n",
      " [-2.85385757]\n",
      " [ 0.3348794 ]\n",
      " [ 1.54505771]\n",
      " [ 3.76039123]\n",
      " [-3.08866171]\n",
      " [-0.51838654]\n",
      " [ 4.079594  ]\n",
      " [ 3.20824974]\n",
      " [ 4.02375764]\n",
      " [ 1.82350012]\n",
      " [ 2.73740613]\n",
      " [ 4.83990623]\n",
      " [ 4.78336779]\n",
      " [-2.28676607]\n",
      " [-2.59697585]\n",
      " [-4.13702962]\n",
      " [-2.42724456]\n",
      " [ 4.51397344]\n",
      " [-4.76847074]\n",
      " [ 4.55519664]\n",
      " [ 4.76617981]\n",
      " [-0.63032856]\n",
      " [-4.11676195]\n",
      " [ 1.24741552]\n",
      " [-3.9683488 ]\n",
      " [-1.08071633]\n",
      " [-0.25369959]\n",
      " [-2.47735284]\n",
      " [ 2.05335703]\n",
      " [ 4.89243931]\n",
      " [ 2.84978551]\n",
      " [ 0.31243966]\n",
      " [ 4.83657486]\n",
      " [ 0.43747194]\n",
      " [-0.77572563]\n",
      " [ 3.27644737]\n",
      " [-1.55841983]\n",
      " [ 0.09359911]\n",
      " [ 2.1735441 ]\n",
      " [ 1.83173806]\n",
      " [ 4.21374777]\n",
      " [ 2.44924523]\n",
      " [-0.69330504]\n",
      " [-1.93368367]\n",
      " [ 4.97225515]\n",
      " [ 2.40465098]\n",
      " [-2.23907213]\n",
      " [ 4.66306122]\n",
      " [-2.9983419 ]\n",
      " [-2.31792161]\n",
      " [-4.7092036 ]\n",
      " [ 2.54629324]\n",
      " [ 3.39634   ]\n",
      " [ 4.70833798]\n",
      " [ 4.21943738]\n",
      " [-3.46481252]\n",
      " [-4.70657762]\n",
      " [-0.37296535]\n",
      " [ 0.14072207]\n",
      " [ 4.26372857]\n",
      " [ 4.68691278]\n",
      " [ 1.20068953]\n",
      " [-4.92552407]\n",
      " [ 0.61007361]\n",
      " [ 3.98499229]\n",
      " [ 2.98152954]\n",
      " [ 4.09879831]\n",
      " [ 4.92827865]\n",
      " [-2.10621153]\n",
      " [ 3.96988303]\n",
      " [ 1.05428171]\n",
      " [-1.58649877]\n",
      " [ 2.41262391]\n",
      " [-4.68382943]\n",
      " [-3.00209887]\n",
      " [ 2.17824054]\n",
      " [ 4.62864372]\n",
      " [-3.42174215]\n",
      " [ 3.24110498]\n",
      " [-4.59041032]\n",
      " [-0.10349687]\n",
      " [ 4.74605444]\n",
      " [-4.81932749]\n",
      " [ 2.84527302]\n",
      " [-2.46052222]\n",
      " [ 0.05968899]\n",
      " [ 3.07686272]\n",
      " [-1.19205355]\n",
      " [-1.54193042]\n",
      " [-4.46625195]\n",
      " [-4.83257391]\n",
      " [ 0.41097987]\n",
      " [-4.00972237]\n",
      " [ 2.56088925]\n",
      " [ 3.2564741 ]]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "nsample = 1000\n",
    "nvariables = 100\n",
    "X0=np.ones([nsample, 1])\n",
    "X1=np.random.uniform(0, 10, ([nsample,nvariables]))\n",
    "X=np.concatenate([X0, X1], axis=1)\n",
    "error=np.random.normal(0, 1, (nsample,1)) # Normal random error\n",
    "beta=np.random.uniform(-5, 5, size=([nvariables+1, 1]))\n",
    "Y=np.dot(X, beta)+error\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A)\n",
    "Estimate the value of the regression coefficients by using the analytical solution for the least squares\n",
    "estimation problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('time elapsed=', 0.0023641579900868237)\n",
      "[[ 1.73944484]\n",
      " [ 2.11849576]\n",
      " [-3.3627126 ]\n",
      " [ 2.49636401]\n",
      " [-2.84054722]\n",
      " [ 2.02156168]\n",
      " [-2.86232325]\n",
      " [ 0.35178602]\n",
      " [ 1.543078  ]\n",
      " [ 3.75664986]\n",
      " [-3.10144696]\n",
      " [-0.49563234]\n",
      " [ 4.07457553]\n",
      " [ 3.19734595]\n",
      " [ 4.01312126]\n",
      " [ 1.81554646]\n",
      " [ 2.73727512]\n",
      " [ 4.86453595]\n",
      " [ 4.78753664]\n",
      " [-2.28646111]\n",
      " [-2.60981044]\n",
      " [-4.13475238]\n",
      " [-2.42150444]\n",
      " [ 4.51678882]\n",
      " [-4.76576907]\n",
      " [ 4.55297872]\n",
      " [ 4.76157291]\n",
      " [-0.63205529]\n",
      " [-4.11615598]\n",
      " [ 1.24171108]\n",
      " [-3.95975354]\n",
      " [-1.08472859]\n",
      " [-0.25454118]\n",
      " [-2.45531301]\n",
      " [ 2.04235535]\n",
      " [ 4.90231666]\n",
      " [ 2.83335418]\n",
      " [ 0.28134911]\n",
      " [ 4.84884805]\n",
      " [ 0.42513108]\n",
      " [-0.79616354]\n",
      " [ 3.25057585]\n",
      " [-1.57517965]\n",
      " [ 0.0961234 ]\n",
      " [ 2.17431404]\n",
      " [ 1.82505696]\n",
      " [ 4.22074613]\n",
      " [ 2.44749707]\n",
      " [-0.70609706]\n",
      " [-1.94542769]\n",
      " [ 4.95931038]\n",
      " [ 2.40542927]\n",
      " [-2.24506929]\n",
      " [ 4.64658585]\n",
      " [-2.99305659]\n",
      " [-2.30420422]\n",
      " [-4.70322873]\n",
      " [ 2.55568737]\n",
      " [ 3.39306073]\n",
      " [ 4.69860549]\n",
      " [ 4.21740776]\n",
      " [-3.46522597]\n",
      " [-4.70731893]\n",
      " [-0.38375324]\n",
      " [ 0.15328952]\n",
      " [ 4.26222374]\n",
      " [ 4.69090512]\n",
      " [ 1.21393678]\n",
      " [-4.91855814]\n",
      " [ 0.60281507]\n",
      " [ 3.99072754]\n",
      " [ 2.98359187]\n",
      " [ 4.1058776 ]\n",
      " [ 4.92828094]\n",
      " [-2.10718704]\n",
      " [ 3.9875125 ]\n",
      " [ 1.06448384]\n",
      " [-1.58946094]\n",
      " [ 2.42858799]\n",
      " [-4.70019775]\n",
      " [-2.99818303]\n",
      " [ 2.16842197]\n",
      " [ 4.62660575]\n",
      " [-3.42353357]\n",
      " [ 3.24789051]\n",
      " [-4.59425366]\n",
      " [-0.09865654]\n",
      " [ 4.73365641]\n",
      " [-4.82251921]\n",
      " [ 2.85609984]\n",
      " [-2.43892912]\n",
      " [ 0.05248573]\n",
      " [ 3.066192  ]\n",
      " [-1.18456813]\n",
      " [-1.53919184]\n",
      " [-4.4824774 ]\n",
      " [-4.83151957]\n",
      " [ 0.41117392]\n",
      " [-4.02762808]\n",
      " [ 2.57962647]\n",
      " [ 3.24912254]]\n"
     ]
    }
   ],
   "source": [
    "time_start = time.clock()\n",
    "beta_ls_exact=np.dot(np.dot(np.linalg.inv(np.dot(np.transpose(X),X)),np.transpose(X)),Y)\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print('time elapsed=',time_elapsed)\n",
    "print(beta_ls_exact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0977724073092068, 1.0434809952479307, 2.4665810510725774, 6.714342056905366, 0.99945970610573576, 1.3579490130539547, 6.6804736051702136, 16.2173602447095, 2.0595882724731904, 13.886308752737673, 11.742043116178328, 4.7058005551245303, 4.674682595374434, 15.484317482790741, 21.873975836452829, 10.694079438587542, 9.3725619835101668, 13.050946999504074]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhoAAAGHCAYAAAD2qfsmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnTFoSJKkzvw/bIE30nDci9sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe453c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "lambda_est=[]\n",
    "sigma=np.arange(1,10, 0.5)\n",
    "\n",
    "for i in sigma :\n",
    "    error=np.random.normal(0, i, (nsample,1)) # Normal random error with different sigma\n",
    "    Y=np.dot(X, beta)+error\n",
    "    beta_ls_exact=np.dot(np.dot(np.linalg.inv(np.dot(np.transpose(X),X)),np.transpose(X)),Y)\n",
    "    lambda_est.append((np.linalg.norm(beta-beta_ls_exact,ord=2)/np.linalg.norm(beta,ord=2))*100)\n",
    "    \n",
    "print lambda_est\n",
    "\n",
    "\n",
    "plt.plot(lambda_est, 'bs')\n",
    "plt.xlabel('Sigma')\n",
    "plt.ylabel('Lambda')\n",
    "plt.title('Lambda Vs. Sigma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C)\n",
    "Estimate the value of the regression coefficients (least squares) by using the tool minimize from the\n",
    "python package Scipy.optimize. Try at least three available solvers and compare their performance\n",
    "(iterations, function, gradient and hessian evaluations as well as total computational time).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 84919.433779\n",
      "         Iterations: 13\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 27\n",
      "         Hessian evaluations: 13\n",
      "('time elapsed=', 0.01405822801461909)\n",
      "[-2.82008067  2.18757466 -3.33272327  2.40049448 -2.91963727  2.00327112\n",
      " -2.92131844  0.38737346  1.41670753  3.80403476 -3.04939229 -0.58693961\n",
      "  4.13023388  3.2712188   4.06065034  1.86865285  2.90094534  5.10282956\n",
      "  4.75282604 -2.3773995  -2.74905144 -3.94538837 -2.45767374  4.49870427\n",
      " -4.74963116  4.5581906   4.65647517 -0.59536712 -4.19275214  1.24511272\n",
      " -3.89736906 -1.04011949 -0.2648055  -2.28654196  2.16801341  4.92252474\n",
      "  2.94042701  0.53332892  4.79756196  0.43628567 -0.86060568  3.35301637\n",
      " -1.41157385  0.06995832  2.14622713  1.82173066  4.29591559  2.45075603\n",
      " -0.63613901 -1.91125291  4.94260168  2.30714525 -2.39602297  4.6346139\n",
      " -3.05933576 -2.51372002 -4.71725957  2.5502426   3.42703598  4.78687509\n",
      "  4.21202156 -3.54248362 -4.50429966 -0.48099936  0.13159525  4.24485933\n",
      "  4.77287047  1.38593122 -4.99300658  0.74922483  3.95908503  2.79126195\n",
      "  3.99975694  4.84343316 -2.07182145  3.98490325  1.19556984 -1.65011529\n",
      "  2.41928262 -4.77430334 -2.80623367  2.12898233  4.6608253  -3.45711524\n",
      "  3.31431846 -4.59174864 -0.0981681   4.70477634 -4.95014163  2.87792685\n",
      " -2.4599172   0.12189708  2.88425646 -1.36533708 -1.58816479 -4.39826269\n",
      " -4.80547961  0.56007547 -3.78563627  2.50914512  3.30404331]\n",
      "('error=', 1.3659231966901152e-06)\n"
     ]
    }
   ],
   "source": [
    "# c : Newton-CG\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def least_sq_reg_der(beta_ls,X,Y):\n",
    "    beta_ls=np.matrix(beta_ls)\n",
    "    pp=-2*np.dot(np.transpose(Y-np.dot(X,np.transpose(beta_ls))),X)\n",
    "    return np.squeeze(np.asarray(pp))\n",
    "        \n",
    "        \n",
    "def least_sq_reg_hess(beta_ls,X,Y):\n",
    "    return 2*np.dot(np.transpose(X),X)\n",
    "\n",
    "\n",
    "\n",
    "time_start = time.clock()\n",
    "res = minimize(least_sq_reg, beta_ls0, args=(X,Y), method = 'Newton-CG',jac=least_sq_reg_der, hess=least_sq_reg_hess, options = {'disp': True})\n",
    "time_elapsed = (time.clock() - time_start) \n",
    "print('time elapsed=',time_elapsed)\n",
    "print(res.x)\n",
    "np.linalg.inv(least_sq_reg_hess(res.x,X,Y))\n",
    "print('error=',np.linalg.norm(np.transpose(beta_ls_exact)-res.x,ord=2)/np.linalg.norm(np.transpose(beta_ls_exact),ord=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 84919.433768\n",
      "         Iterations: 6\n",
      "         Function evaluations: 7\n",
      "         Gradient evaluations: 7\n",
      "         Hessian evaluations: 6\n",
      "('time elapsed=', 0.008869112425600179)\n",
      "[-2.82009166  2.18757262 -3.33272408  2.40050035 -2.91964431  2.00327309\n",
      " -2.92131935  0.38737545  1.41670728  3.80403217 -3.04939149 -0.58693972\n",
      "  4.13024247  3.27121943  4.06064646  1.86865365  2.9009471   5.1028255\n",
      "  4.75282718 -2.37740208 -2.74905513 -3.94539386 -2.45767779  4.49870622\n",
      " -4.74962366  4.55818668  4.65647563 -0.59536061 -4.19274504  1.24511478\n",
      " -3.8973661  -1.04011885 -0.26481368 -2.28654173  2.16800687  4.92252054\n",
      "  2.94043056  0.5333243   4.79756441  0.43627901 -0.86060974  3.35301358\n",
      " -1.41157203  0.06996948  2.14622611  1.8217317   4.29591723  2.45076112\n",
      " -0.63614187 -1.91125437  4.94259785  2.30714669 -2.39602395  4.63460325\n",
      " -3.05933115 -2.51371899 -4.71726272  2.55024272  3.42703614  4.7868769\n",
      "  4.21201842 -3.5424867  -4.50429917 -0.48099319  0.1316062   4.24485554\n",
      "  4.7728776   1.38593473 -4.99300561  0.74922867  3.95908786  2.79126176\n",
      "  3.99975326  4.84343426 -2.07181554  3.98489739  1.19557716 -1.65011212\n",
      "  2.41928082 -4.7743059  -2.80624142  2.12898243  4.66082827 -3.45711962\n",
      "  3.31431908 -4.59174474 -0.0981666   4.70477382 -4.95014286  2.87792284\n",
      " -2.45991397  0.12189604  2.88425693 -1.36533547 -1.58816079 -4.39826434\n",
      " -4.8054921   0.56007872 -3.78564008  2.50915003  3.30404243]\n",
      "('error=', 4.2990732639375794e-12)\n"
     ]
    }
   ],
   "source": [
    "# c: dogleg\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def least_sq_reg_der(beta_ls,X,Y):\n",
    "    beta_ls=np.matrix(beta_ls)\n",
    "    pp=-2*np.dot(np.transpose(Y-np.dot(X,np.transpose(beta_ls))),X)\n",
    "    return np.squeeze(np.asarray(pp))\n",
    "        \n",
    "        \n",
    "def least_sq_reg_hess(beta_ls,X,Y):\n",
    "    return 2*np.dot(np.transpose(X),X)\n",
    "\n",
    "\n",
    "\n",
    "time_start = time.clock()\n",
    "res = minimize(least_sq_reg, beta_ls0, args=(X,Y), method = 'dogleg',jac=least_sq_reg_der, hess=least_sq_reg_hess, options = {'disp': True})\n",
    "time_elapsed = (time.clock() - time_start) \n",
    "print('time elapsed=',time_elapsed)\n",
    "print(res.x)\n",
    "np.linalg.inv(least_sq_reg_hess(res.x,X,Y))\n",
    "print('error=',np.linalg.norm(np.transpose(beta_ls_exact)-res.x,ord=2)/np.linalg.norm(np.transpose(beta_ls_exact),ord=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def least_sq_reg(beta_ls, X, Y):\n",
    "    beta_ls=np.matrix(beta_ls)\n",
    "    z=Y-X*np.transpose(beta_ls)\n",
    "    return np.dot(np.transpose(z),z) #sum of the square errors, value of the obj function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 84919.433768\n",
      "         Iterations: 131\n",
      "         Function evaluations: 24515\n",
      "         Gradient evaluations: 238\n",
      "('time elapsed=', 1.4608064334461233)\n",
      "[-2.8200985   2.18757251 -3.33272404  2.40050027 -2.9196443   2.00327308\n",
      " -2.92131936  0.3873754   1.41670726  3.80403212 -3.04939138 -0.5869397\n",
      "  4.13024253  3.27121944  4.0606465   1.86865365  2.90094716  5.10282556\n",
      "  4.75282723 -2.3774021  -2.74905506 -3.94539385 -2.45767775  4.49870628\n",
      " -4.74962365  4.5581867   4.65647564 -0.59536055 -4.19274501  1.2451148\n",
      " -3.89736611 -1.04011893 -0.2648137  -2.28654166  2.1680069   4.92252054\n",
      "  2.94043061  0.53332426  4.79756441  0.43627895 -0.86060973  3.35301358\n",
      " -1.411572    0.06996955  2.14622612  1.82173174  4.29591722  2.45076115\n",
      " -0.63614186 -1.91125438  4.94259787  2.30714665 -2.39602388  4.63460324\n",
      " -3.05933111 -2.51371897 -4.71726272  2.55024273  3.42703609  4.78687685\n",
      "  4.2120184  -3.54248668 -4.50429913 -0.48099318  0.13160623  4.24485561\n",
      "  4.77287762  1.38593473 -4.99300558  0.7492287   3.95908792  2.79126178\n",
      "  3.99975324  4.84343427 -2.07181555  3.98489735  1.19557716 -1.65011214\n",
      "  2.41928088 -4.77430592 -2.80624141  2.12898241  4.66082837 -3.45711963\n",
      "  3.31431909 -4.59174468 -0.09816652  4.70477388 -4.95014286  2.8779229\n",
      " -2.45991397  0.12189603  2.8842569  -1.36533542 -1.58816079 -4.39826433\n",
      " -4.80549213  0.56007879 -3.78564002  2.50914997  3.30404246]\n",
      "('error=', 2.1148376814635847e-07)\n"
     ]
    }
   ],
   "source": [
    "# c :BFGS\n",
    "\n",
    "beta_ls0 = np.zeros(nvariables+1) #we need to initiate our initial point\n",
    "time_start = time.clock()\n",
    "res = minimize(least_sq_reg, beta_ls0, args=(X,Y), method = 'BFGS', options = {'disp': True}) #arguments for the model are X and Y\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print('time elapsed=',time_elapsed)\n",
    "print (res.x) \n",
    "print('error=',np.linalg.norm(np.transpose(beta_ls_exact)-res.x,ord=2)/np.linalg.norm(np.transpose(beta_ls_exact),ord=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: [[ 84919.43438612]]\n",
      "            Iterations: 62\n",
      "            Function evaluations: 6628\n",
      "            Gradient evaluations: 62\n",
      "('time elapsed=', 0.38456415182736237)\n",
      "[-2.81999282  2.18757499 -3.33274337  2.40049986 -2.91964145  2.00328562\n",
      " -2.92135673  0.38740984  1.41667548  3.8040489  -3.04938633 -0.58696508\n",
      "  4.13026249  3.2712273   4.06064785  1.86863405  2.90094692  5.10280418\n",
      "  4.75279975 -2.37740227 -2.74908372 -3.94539617 -2.45771762  4.49873764\n",
      " -4.7495816   4.55816327  4.65648354 -0.5953383  -4.19275952  1.24510698\n",
      " -3.89736525 -1.04011663 -0.26475866 -2.28654486  2.16800036  4.92250585\n",
      "  2.94045632  0.53331927  4.79756062  0.43632093 -0.86062636  3.35304649\n",
      " -1.41155463  0.07002751  2.14629284  1.82174526  4.29594552  2.45075327\n",
      " -0.63611914 -1.9112522   4.94254981  2.3071427  -2.39602753  4.63456411\n",
      " -3.05933373 -2.51372557 -4.71728558  2.55019751  3.42705259  4.78684688\n",
      "  4.21203778 -3.54249077 -4.50430907 -0.48098153  0.13159908  4.24482322\n",
      "  4.77287968  1.38597311 -4.99303748  0.74922122  3.95905633  2.79125096\n",
      "  3.99978166  4.84342029 -2.07179286  3.98486089  1.19553417 -1.6501765\n",
      "  2.41921376 -4.77430548 -2.80619574  2.12901886  4.66084734 -3.45709624\n",
      "  3.31433304 -4.59175443 -0.09815162  4.70480099 -4.95015551  2.87791769\n",
      " -2.45999135  0.12189591  2.88425535 -1.36529894 -1.58814319 -4.39827985\n",
      " -4.80542618  0.56006648 -3.78563869  2.50912917  3.30408075]\n",
      "('error=', 9.0791862297303001e-06)\n"
     ]
    }
   ],
   "source": [
    "# c :SLSQP\n",
    "\n",
    "beta_ls0 = np.zeros(nvariables+1) #we need to initiate our initial point\n",
    "time_start = time.clock()\n",
    "res = minimize(least_sq_reg, beta_ls0, args=(X,Y), method = 'SLSQP', options = {'disp': True}) #arguments for the model are X and Y\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print('time elapsed=',time_elapsed)\n",
    "print (res.x) \n",
    "print('error=',np.linalg.norm(np.transpose(beta_ls_exact)-res.x,ord=2)/np.linalg.norm(np.transpose(beta_ls_exact),ord=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 84919.438062\n",
      "         Iterations: 243\n",
      "         Function evaluations: 55632\n",
      "         Gradient evaluations: 540\n",
      "('time elapsed=', 2.9277961149491603)\n",
      "[-2.85789181  2.1876595  -3.33265676  2.40058637 -2.91958424  2.0033621\n",
      " -2.92124797  0.38743794  1.41677483  3.8040492  -3.04932774 -0.58686475\n",
      "  4.13034603  3.27131329  4.06073374  1.86871524  2.90101457  5.10290849\n",
      "  4.75291173 -2.37733101 -2.74897404 -3.94534963 -2.45755214  4.4987615\n",
      " -4.74954624  4.55825218  4.65654622 -0.59529921 -4.19269757  1.24517746\n",
      " -3.89728324 -1.04006126 -0.26472422 -2.28641039  2.16808449  4.92261235\n",
      "  2.94051853  0.5333913   4.7976289   0.43632826 -0.86052493  3.35309622\n",
      " -1.41149609  0.07004405  2.14633029  1.8218001   4.2959728   2.45083466\n",
      " -0.63607714 -1.91116057  4.94266668  2.30720999 -2.39592101  4.63465029\n",
      " -3.05928473 -2.5136702  -4.7171507   2.5503713   3.42710086  4.78695988\n",
      "  4.21207411 -3.54236985 -4.50420913 -0.48090851  0.13170382  4.24491855\n",
      "  4.77296519  1.3860117  -4.99294112  0.74922996  3.95915735  2.79134114\n",
      "  3.99980412  4.84347789 -2.0717737   3.98497698  1.19565988 -1.65003571\n",
      "  2.41931526 -4.77427489 -2.80616743  2.12906819  4.66091626 -3.45704269\n",
      "  3.3143886  -4.59171885 -0.09806332  4.70488323 -4.95006486  2.87796457\n",
      " -2.45985323  0.12197447  2.88435942 -1.36521473 -1.58804764 -4.39818139\n",
      " -4.8054392   0.56020827 -3.78554284  2.50927804  3.30413515]\n",
      "('error=', 0.0011659627184107803)\n"
     ]
    }
   ],
   "source": [
    "# c : CG\n",
    "\n",
    "beta_ls0 = np.zeros(nvariables+1) #we need to initiate our initial point\n",
    "time_start = time.clock()\n",
    "res = minimize(least_sq_reg, beta_ls0, args=(X,Y), method = 'CG', options = {'disp': True}) #arguments for the model are X and Y\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print('time elapsed=',time_elapsed)\n",
    "print (res.x) \n",
    "print('error=',np.linalg.norm(np.transpose(beta_ls_exact)-res.x,ord=2)/np.linalg.norm(np.transpose(beta_ls_exact),ord=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current function value</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Function evaluations</th>\n",
       "      <th>Gradient evaluations</th>\n",
       "      <th>Hessian evaluations</th>\n",
       "      <th>Time elapsed</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Newton-CG</th>\n",
       "      <td>84919.433779</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>1.370000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogleg</th>\n",
       "      <td>84919.434768</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>4.300000e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFGS</th>\n",
       "      <td>84919.433758</td>\n",
       "      <td>131</td>\n",
       "      <td>24515</td>\n",
       "      <td>238</td>\n",
       "      <td>NA</td>\n",
       "      <td>1.4600</td>\n",
       "      <td>2.110000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLSQP</th>\n",
       "      <td>84919.434386</td>\n",
       "      <td>62</td>\n",
       "      <td>6628</td>\n",
       "      <td>62</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>9.080000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CG</th>\n",
       "      <td>84919.438062</td>\n",
       "      <td>243</td>\n",
       "      <td>55632</td>\n",
       "      <td>540</td>\n",
       "      <td>NA</td>\n",
       "      <td>2.9300</td>\n",
       "      <td>1.200000e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Current function value  Iteration  Function evaluations  \\\n",
       "Newton-CG            84919.433779         13                    15   \n",
       "dogleg               84919.434768          6                     7   \n",
       "BFGS                 84919.433758        131                 24515   \n",
       "SLSQP                84919.434386         62                  6628   \n",
       "CG                   84919.438062        243                 55632   \n",
       "\n",
       "           Gradient evaluations Hessian evaluations  Time elapsed  \\\n",
       "Newton-CG                    27                  13        0.0140   \n",
       "dogleg                        7                   6        0.0089   \n",
       "BFGS                        238                  NA        1.4600   \n",
       "SLSQP                        62                  NA        0.3800   \n",
       "CG                          540                  NA        2.9300   \n",
       "\n",
       "                  Error  \n",
       "Newton-CG  1.370000e-06  \n",
       "dogleg     4.300000e-12  \n",
       "BFGS       2.110000e-07  \n",
       "SLSQP      9.080000e-06  \n",
       "CG         1.200000e-03  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sympy\n",
    "from pandas import DataFrame\n",
    "from sympy import *\n",
    "\n",
    "# For Final report we need to put 'Current function value', 'Iteration','Function eval', 'Gradient eval','Hessian eval', 'Time elapsed', 'Error'\n",
    "### Fill value instead of 1 2 3 .....\n",
    "t = [[84919.433779 ,13 ,15 ,27 ,13 ,0.014 ,1.37e-6 ], #Newton-CG\n",
    "     [84919.434768 , 6, 7 ,7 ,6 , 0.0089 ,4.30e-12 ], #dogleg\n",
    "     [84919.433758 , 131,24515 ,238 ,\"NA\" ,1.46 ,2.11e-7 ], #BFGS\n",
    "     [84919.434386 ,62 ,6628 ,62 ,\"NA\" ,0.38 ,9.08e-6 ], #SLSQP\n",
    "     [84919.438062 ,243 ,55632 ,540 ,\"NA\" ,2.93 ,0.0012 ]] #CG\n",
    "\n",
    "\n",
    "table = DataFrame(t, index=['Newton-CG', 'dogleg', 'BFGS', 'SLSQP', 'CG'], columns=['Current function value', 'Iteration',\n",
    "                                                                                    'Function evaluations', 'Gradient evaluations',\n",
    "                                                                                    'Hessian evaluations', 'Time elapsed', 'Error'])\n",
    "table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D)\n",
    "Considering again the least squares estimation problem, estimate the value of the regression coefficients\n",
    "by implementing the:\n",
    "\n",
    "i. Gradient method\n",
    "\n",
    "ii. Newton method\n",
    "\n",
    "iii. Quasi-Newton method\n",
    "\n",
    "Consider a like search technique to improve the algorithm convergence, e.x., Armijo rule. Compare the\n",
    "performance of these algorithms (iterations, function, gradient and hessian evaluations as well as total\n",
    "computational time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#definitinition of OF #objective function\n",
    "def least_sq_reg(beta_ls, X, Y):\n",
    "    beta_ls=np.matrix(beta_ls)\n",
    "    z=Y-X*np.transpose(beta_ls)\n",
    "    return np.transpose(z)*z\n",
    "\n",
    "#definition of Gradient\n",
    "def least_sq_reg_der(beta_ls,X,Y):\n",
    "    beta_ls=np.matrix(beta_ls)\n",
    "    pp=-2*np.transpose(Y-X*np.transpose(beta_ls))*X\n",
    "    aa= np.squeeze(np.asarray(pp))\n",
    "    return aa\n",
    "\n",
    "#definition of hessian\n",
    "def least_sq_reg_hess(beta_ls,X,Y):\n",
    "    ss=2*np.dot(np.transpose(X),X)\n",
    "    return ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i) Gradient method\n",
    "\n",
    " $\\rightarrow$ From an initial iterate $x_0$\n",
    "\n",
    "$\\rightarrow$ Compute search (descent) directions $p_k$\n",
    "\n",
    "$\\rightarrow$ Far from the solution, compute a steplength $\\alpha_k>0$\n",
    "\n",
    "$\\rightarrow$ Movement:\n",
    "$$x_{k+1} = x_k + \\alpha_k\\ p_k$$\n",
    "Until convergence to a local solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('time elapsed=', 215.57388964362326)\n",
      "('iterations', 99999)\n",
      "84929.3073365\n",
      "[-1.00552324  2.18336177 -3.33600171  2.39643687 -2.92246059  1.99875166\n",
      " -2.92468279  0.38429239  1.41333943  3.80317979 -3.05248791 -0.59071866\n",
      "  4.12524893  3.26656723  4.05649917  1.86564815  2.8978303   5.09889964\n",
      "  4.74850713 -2.38069513 -2.75260615 -3.94742467 -2.46350012  4.49601821\n",
      " -4.75297247  4.55537918  4.65282515 -0.59800657 -4.19509426  1.24210405\n",
      " -3.90135134 -1.04271539 -0.26901538 -2.29302437  2.16423839  4.91800017\n",
      "  2.93592439  0.53012202  4.79433681  0.43390435 -0.86465576  3.34852329\n",
      " -1.41526794  0.06632625  2.14111084  1.81840842  4.29306879  2.44703809\n",
      " -0.63913949 -1.91576422  4.93924581  2.30399171 -2.40088197  4.63240874\n",
      " -3.06169684 -2.5159778  -4.72248466  2.54384261  3.42392076  4.7828991\n",
      "  4.20934812 -3.54783455 -4.50863292 -0.48497834  0.1268127   4.24195353\n",
      "  4.76853478  1.38218161 -4.99625161  0.74897886  3.95538557  2.78762389\n",
      "  3.99727475  4.84105212 -2.0735365   3.98123654  1.19165168 -1.65348411\n",
      "  2.41727442 -4.77572941 -2.80935509  2.12472609  4.65639364 -3.46088663\n",
      "  3.31067667 -4.59263375 -0.10338909  4.6996278  -4.95383034  2.87600641\n",
      " -2.46276516  0.11816647  2.87931377 -1.37122449 -1.59362318 -4.40189991\n",
      " -4.80763108  0.55374605 -3.79003875  2.50319568  3.29974066]\n",
      "[[-2.82009166  2.18757262 -3.33272408  2.40050035 -2.91964431  2.00327309\n",
      "  -2.92131935  0.38737545  1.41670728  3.80403217 -3.04939149 -0.58693972\n",
      "   4.13024247  3.27121943  4.06064646  1.86865365  2.9009471   5.1028255\n",
      "   4.75282718 -2.37740208 -2.74905513 -3.94539386 -2.45767779  4.49870622\n",
      "  -4.74962366  4.55818668  4.65647563 -0.59536061 -4.19274504  1.24511478\n",
      "  -3.8973661  -1.04011885 -0.26481368 -2.28654173  2.16800687  4.92252054\n",
      "   2.94043056  0.5333243   4.79756441  0.43627901 -0.86060974  3.35301358\n",
      "  -1.41157203  0.06996948  2.14622611  1.8217317   4.29591723  2.45076112\n",
      "  -0.63614187 -1.91125437  4.94259785  2.30714669 -2.39602395  4.63460325\n",
      "  -3.05933115 -2.51371899 -4.71726272  2.55024272  3.42703614  4.7868769\n",
      "   4.21201842 -3.5424867  -4.50429917 -0.48099319  0.1316062   4.24485554\n",
      "   4.7728776   1.38593473 -4.99300561  0.74922867  3.95908786  2.79126176\n",
      "   3.99975326  4.84343426 -2.07181554  3.98489739  1.19557716 -1.65011212\n",
      "   2.41928082 -4.7743059  -2.80624142  2.12898243  4.66082827 -3.45711962\n",
      "   3.31431908 -4.59174474 -0.0981666   4.70477382 -4.95014286  2.87792284\n",
      "  -2.45991397  0.12189604  2.88425693 -1.36533547 -1.58816079 -4.39826434\n",
      "  -4.8054921   0.56007872 -3.78564008  2.50915003  3.30404243]]\n",
      "('Tolerance=', 11.957228882608536)\n",
      "('error=', 0.056169323979137355)\n"
     ]
    }
   ],
   "source": [
    "### With Armijo Rule\n",
    "\n",
    "(a,b)=X.shape\n",
    "beta_lsg=np.zeros(b) #initial value for beta\n",
    "#alpha= 0.0000001\n",
    "n_iter=100000 #maximim nunber iteration\n",
    "OF_iter=np.zeros(n_iter)\n",
    "tol_iter=np.zeros(n_iter)\n",
    "alpha_iter=np.zeros(n_iter)\n",
    "i=0;\n",
    "tol=1000; # Tolerance\n",
    "epsilon=1e-3;\n",
    "\n",
    "time_start = time.clock()\n",
    "while (i <= n_iter-2) and (tol>epsilon):\n",
    "    i=i+1\n",
    "    grad=least_sq_reg_der(beta_lsg,X,Y) #this function gives us the value of the gradient\n",
    "    ddirect=-grad\n",
    "    ########################\n",
    "    #     Armijo Rule\n",
    "    sigma=0.1\n",
    "    beta=0.5\n",
    "    alpha=1\n",
    "    while (least_sq_reg(beta_lsg+alpha*ddirect,X,Y)> least_sq_reg(beta_lsg,X,Y)+alpha*sigma*np.dot(grad,ddirect)):\n",
    "        alpha=alpha*beta\n",
    "    ########################\n",
    "    beta_lsg=beta_lsg+alpha*ddirect\n",
    "    OF_iter[i]=least_sq_reg(beta_lsg,X,Y) # Objective Function ---Residuals\n",
    "    tol=np.linalg.norm(grad,ord=2)\n",
    "    tol_iter[i]=tol\n",
    "    \n",
    "time_elapsed = (time.clock() - time_start) \n",
    "print('time elapsed=',time_elapsed)\n",
    "print('iterations',i)\n",
    "print(OF_iter[i])\n",
    "print(beta_lsg)\n",
    "print(np.transpose(beta_ls_exact))\n",
    "print('Tolerance=',tol)\n",
    "print('error=',np.linalg.norm(np.transpose(beta_ls_exact)-beta_lsg,ord=2)/np.linalg.norm(beta_lsg,ord=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('time elapsed=', 14.0880259515543)\n",
      "('iterations', 99999)\n",
      "84942.527301\n",
      "[-0.0449488   2.18113141 -3.33773806  2.39428447 -2.92395271  1.99635687\n",
      " -2.92646459  0.38265903  1.41155527  3.80272724 -3.05412837 -0.59272041\n",
      "  4.12260421  3.26410322  4.05430245  1.86405585  2.89617906  5.09682015\n",
      "  4.74621892 -2.38243967 -2.75448725 -3.94850098 -2.46658356  4.49459399\n",
      " -4.75474652  4.55389168  4.65089142 -0.59940854 -4.19633916  1.24050891\n",
      " -3.90346229 -1.04409118 -0.27124091 -2.29645735  2.16224217  4.91560592\n",
      "  2.93353771  0.52842552  4.79262692  0.43264598 -0.86679887  3.34614498\n",
      " -1.41722575  0.06439638  2.13840169  1.8166479   4.29155963  2.44506596\n",
      " -0.64072767 -1.91815287  4.93747005  2.30232025 -2.40345492  4.63124573\n",
      " -3.06295048 -2.51717478 -4.72525025  2.54045333  3.4222703   4.78079204\n",
      "  4.20793326 -3.55066681 -4.51092836 -0.48708925  0.12427388  4.240416\n",
      "  4.76623454  1.38019354 -4.99797124  0.74884532  3.95342441  2.78569681\n",
      "  3.99596141  4.83978978 -2.07444881  3.9792973   1.18957239 -1.65527045\n",
      "  2.41621101 -4.77648427 -2.81100466  2.1224716   4.65404478 -3.46288209\n",
      "  3.30874722 -4.59310568 -0.106155    4.69690238 -4.95578365  2.87499064\n",
      " -2.46427576  0.11619089  2.87669574 -1.37434324 -1.59651609 -4.40382578\n",
      " -4.80876468  0.55039243 -3.7923686   2.50004233  3.29746211]\n",
      "[[-2.82009166  2.18757262 -3.33272408  2.40050035 -2.91964431  2.00327309\n",
      "  -2.92131935  0.38737545  1.41670728  3.80403217 -3.04939149 -0.58693972\n",
      "   4.13024247  3.27121943  4.06064646  1.86865365  2.9009471   5.1028255\n",
      "   4.75282718 -2.37740208 -2.74905513 -3.94539386 -2.45767779  4.49870622\n",
      "  -4.74962366  4.55818668  4.65647563 -0.59536061 -4.19274504  1.24511478\n",
      "  -3.8973661  -1.04011885 -0.26481368 -2.28654173  2.16800687  4.92252054\n",
      "   2.94043056  0.5333243   4.79756441  0.43627901 -0.86060974  3.35301358\n",
      "  -1.41157203  0.06996948  2.14622611  1.8217317   4.29591723  2.45076112\n",
      "  -0.63614187 -1.91125437  4.94259785  2.30714669 -2.39602395  4.63460325\n",
      "  -3.05933115 -2.51371899 -4.71726272  2.55024272  3.42703614  4.7868769\n",
      "   4.21201842 -3.5424867  -4.50429917 -0.48099319  0.1316062   4.24485554\n",
      "   4.7728776   1.38593473 -4.99300561  0.74922867  3.95908786  2.79126176\n",
      "   3.99975326  4.84343426 -2.07181554  3.98489739  1.19557716 -1.65011212\n",
      "   2.41928082 -4.7743059  -2.80624142  2.12898243  4.66082827 -3.45711962\n",
      "   3.31431908 -4.59174474 -0.0981666   4.70477382 -4.95014286  2.87792284\n",
      "  -2.45991397  0.12189604  2.88425693 -1.36533547 -1.58816079 -4.39826434\n",
      "  -4.8054921   0.56007872 -3.78564008  2.50915003  3.30404243]]\n",
      "('Tolerance=', 16.639447266111439)\n",
      "('error=', 0.085955155074071907)\n"
     ]
    }
   ],
   "source": [
    "### Without Armijo Rule\n",
    "\n",
    "(a,b)=X.shape\n",
    "beta_lsg=np.zeros(b) #initial value for beta\n",
    "alpha= 0.0000001\n",
    "n_iter=100000 #maximim nunber iteration\n",
    "OF_iter=np.zeros(n_iter)\n",
    "tol_iter=np.zeros(n_iter)\n",
    "alpha_iter=np.zeros(n_iter)\n",
    "i=0;\n",
    "tol=1000; # Tolerance\n",
    "epsilon=1e-3;\n",
    "\n",
    "time_start = time.clock()\n",
    "while (i <= n_iter-2) and (tol>epsilon):\n",
    "    i=i+1\n",
    "    grad=least_sq_reg_der(beta_lsg,X,Y) #this function gives us the value of the gradient\n",
    "    ddirect=-grad\n",
    "    beta_lsg=beta_lsg+alpha*ddirect\n",
    "    OF_iter[i]=least_sq_reg(beta_lsg,X,Y) # Objective Function ---Residuals\n",
    "    tol=np.linalg.norm(grad,ord=2)\n",
    "    tol_iter[i]=tol\n",
    "    \n",
    "time_elapsed = (time.clock() - time_start) \n",
    "print('time elapsed=',time_elapsed)\n",
    "print('iterations',i)\n",
    "print(OF_iter[i])\n",
    "print(beta_lsg)\n",
    "print(np.transpose(beta_ls_exact))\n",
    "print('Tolerance=',tol)\n",
    "print('error=',np.linalg.norm(np.transpose(beta_ls_exact)-beta_lsg,ord=2)/np.linalg.norm(beta_lsg,ord=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii) Newtons method\n",
    "\n",
    " $\\rightarrow$ From an initial iterate $x_0$\n",
    "\n",
    "$\\rightarrow$ Compute search (descent) directions $p_k=-(\\nabla^2 f(x_k))^{-1} \\nabla f(x_k)$, whenever $\\nabla^2 f(x_k)$ is\n",
    "nonsingular. \n",
    "\n",
    "$\\rightarrow$ Far from the solution, compute a steplength $\\alpha_k>0$\n",
    "\n",
    "$\\rightarrow$ Movement:\n",
    "$$x_{k+1} = x_k + \\alpha_k\\ p_k$$\n",
    "Until convergence to a local solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('time elapsed=', 293.5455931344186)\n",
      "('iterations', 99999)\n",
      "84919.4337684\n",
      "[-2.82009166  2.18757262 -3.33272408  2.40050035 -2.91964431  2.00327309\n",
      " -2.92131935  0.38737545  1.41670728  3.80403217 -3.04939149 -0.58693972\n",
      "  4.13024247  3.27121943  4.06064646  1.86865365  2.9009471   5.1028255\n",
      "  4.75282718 -2.37740208 -2.74905513 -3.94539386 -2.45767779  4.49870622\n",
      " -4.74962366  4.55818668  4.65647563 -0.59536061 -4.19274504  1.24511478\n",
      " -3.8973661  -1.04011885 -0.26481368 -2.28654173  2.16800687  4.92252054\n",
      "  2.94043056  0.5333243   4.79756441  0.43627901 -0.86060974  3.35301358\n",
      " -1.41157203  0.06996948  2.14622611  1.8217317   4.29591723  2.45076112\n",
      " -0.63614187 -1.91125437  4.94259785  2.30714669 -2.39602395  4.63460325\n",
      " -3.05933115 -2.51371899 -4.71726272  2.55024272  3.42703614  4.7868769\n",
      "  4.21201842 -3.5424867  -4.50429917 -0.48099319  0.1316062   4.24485554\n",
      "  4.7728776   1.38593473 -4.99300561  0.74922867  3.95908786  2.79126176\n",
      "  3.99975326  4.84343426 -2.07181554  3.98489739  1.19557716 -1.65011212\n",
      "  2.41928082 -4.7743059  -2.80624142  2.12898243  4.66082827 -3.45711962\n",
      "  3.31431908 -4.59174474 -0.0981666   4.70477382 -4.95014286  2.87792284\n",
      " -2.45991397  0.12189604  2.88425693 -1.36533547 -1.58816079 -4.39826434\n",
      " -4.8054921   0.56007872 -3.78564008  2.50915003  3.30404243]\n",
      "[[-2.82009166  2.18757262 -3.33272408  2.40050035 -2.91964431  2.00327309\n",
      "  -2.92131935  0.38737545  1.41670728  3.80403217 -3.04939149 -0.58693972\n",
      "   4.13024247  3.27121943  4.06064646  1.86865365  2.9009471   5.1028255\n",
      "   4.75282718 -2.37740208 -2.74905513 -3.94539386 -2.45767779  4.49870622\n",
      "  -4.74962366  4.55818668  4.65647563 -0.59536061 -4.19274504  1.24511478\n",
      "  -3.8973661  -1.04011885 -0.26481368 -2.28654173  2.16800687  4.92252054\n",
      "   2.94043056  0.5333243   4.79756441  0.43627901 -0.86060974  3.35301358\n",
      "  -1.41157203  0.06996948  2.14622611  1.8217317   4.29591723  2.45076112\n",
      "  -0.63614187 -1.91125437  4.94259785  2.30714669 -2.39602395  4.63460325\n",
      "  -3.05933115 -2.51371899 -4.71726272  2.55024272  3.42703614  4.7868769\n",
      "   4.21201842 -3.5424867  -4.50429917 -0.48099319  0.1316062   4.24485554\n",
      "   4.7728776   1.38593473 -4.99300561  0.74922867  3.95908786  2.79126176\n",
      "   3.99975326  4.84343426 -2.07181554  3.98489739  1.19557716 -1.65011212\n",
      "   2.41928082 -4.7743059  -2.80624142  2.12898243  4.66082827 -3.45711962\n",
      "   3.31431908 -4.59174474 -0.0981666   4.70477382 -4.95014286  2.87792284\n",
      "  -2.45991397  0.12189604  2.88425693 -1.36533547 -1.58816079 -4.39826434\n",
      "  -4.8054921   0.56007872 -3.78564008  2.50915003  3.30404243]]\n",
      "('Tolerance=', 4972171.1853834139)\n",
      "('error=', 4.2435594497630421e-12)\n"
     ]
    }
   ],
   "source": [
    "### With Armijo Rule\n",
    "\n",
    "(a,b)=X.shape\n",
    "beta_lsg=np.zeros(b) #initial value for beta\n",
    "#alpha= 0.0000001\n",
    "n_iter=100000 #maximim nunber iteration\n",
    "OF_iter=np.zeros(n_iter)\n",
    "tol_iter=np.zeros(n_iter)\n",
    "alpha_iter=np.zeros(n_iter)\n",
    "i=0;\n",
    "tol=1000; # Tolerance\n",
    "epsilon=1e-3;\n",
    "\n",
    "time_start = time.clock()\n",
    "while (i <= n_iter-2) and (tol>epsilon):\n",
    "    i=i+1\n",
    "    grad=least_sq_reg_der(beta_lsg,X,Y)\n",
    "    hess=least_sq_reg_hess(beta_lsg,X,Y) #this function gives us the value of the hessian\n",
    "    ddirect=-(np.dot(np.linalg.inv(hess), grad))\n",
    "    ########################\n",
    "    #     Armijo Rule\n",
    "    sigma=0.1\n",
    "    beta=0.5\n",
    "    alpha=1\n",
    "    while (least_sq_reg(beta_lsg+alpha*ddirect,X,Y)> least_sq_reg(beta_lsg,X,Y)+alpha*sigma*np.dot(grad,ddirect)):\n",
    "        alpha=alpha*beta\n",
    "    ########################\n",
    "    beta_lsg=beta_lsg+alpha*ddirect\n",
    "    OF_iter[i]=least_sq_reg(beta_lsg,X,Y) \n",
    "    tol=np.linalg.norm(hess,ord=2)\n",
    "    tol_iter[i]=tol\n",
    "    \n",
    "time_elapsed = (time.clock() - time_start) \n",
    "print('time elapsed=',time_elapsed)\n",
    "print('iterations',i)\n",
    "print(OF_iter[i])\n",
    "print(beta_lsg)\n",
    "print(np.transpose(beta_ls_exact))\n",
    "print('Tolerance=',tol)\n",
    "print('error=',np.linalg.norm(np.transpose(beta_ls_exact)-beta_lsg,ord=2)/np.linalg.norm(beta_lsg,ord=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('time elapsed=', 192.15463624136464)\n",
      "('iterations', 99999)\n",
      "84611989.3714\n",
      "[-0.0280601   0.0217665  -0.03316083  0.02388514 -0.02905066  0.0199327\n",
      " -0.02906733  0.00385441  0.01409633  0.03785038 -0.03034165 -0.00584009\n",
      "  0.04109619  0.03254885  0.04040371  0.01859323  0.02886462  0.05077346\n",
      "  0.04729095 -0.02365531 -0.02735328 -0.03925694 -0.02445406  0.04476243\n",
      " -0.04725908  0.04535427  0.04633225 -0.00592388 -0.0417181   0.01238898\n",
      " -0.03877906 -0.01034925 -0.00263491 -0.02275125  0.02157182  0.04897941\n",
      "  0.02925748  0.00530661  0.04773609  0.00434101 -0.00856313  0.03336271\n",
      " -0.01404524  0.0006962   0.0213551   0.01812635  0.04274467  0.02438524\n",
      " -0.00632965 -0.01901711  0.04917918  0.02295627 -0.0238406   0.04611462\n",
      " -0.03044055 -0.02501167 -0.04693708  0.02537509  0.03409924  0.04762975\n",
      "  0.04190987 -0.03524798 -0.04481808 -0.00478591  0.00130949  0.0422366\n",
      "  0.04749046  0.01379014 -0.04968074  0.00745488  0.03939319  0.02777324\n",
      "  0.03979782  0.0481925  -0.02061471  0.03965     0.01189607 -0.01641873\n",
      "  0.02407201 -0.04750467 -0.02792229  0.02118352  0.04637556 -0.03439857\n",
      "  0.0329777  -0.04568817 -0.00097676  0.04681282 -0.04925426  0.02863553\n",
      " -0.02447631  0.00121287  0.02869855 -0.01358518 -0.01580231 -0.04376303\n",
      " -0.04781497  0.00557282 -0.03766738  0.02496621  0.03287545]\n",
      "[[-2.82009166  2.18757262 -3.33272408  2.40050035 -2.91964431  2.00327309\n",
      "  -2.92131935  0.38737545  1.41670728  3.80403217 -3.04939149 -0.58693972\n",
      "   4.13024247  3.27121943  4.06064646  1.86865365  2.9009471   5.1028255\n",
      "   4.75282718 -2.37740208 -2.74905513 -3.94539386 -2.45767779  4.49870622\n",
      "  -4.74962366  4.55818668  4.65647563 -0.59536061 -4.19274504  1.24511478\n",
      "  -3.8973661  -1.04011885 -0.26481368 -2.28654173  2.16800687  4.92252054\n",
      "   2.94043056  0.5333243   4.79756441  0.43627901 -0.86060974  3.35301358\n",
      "  -1.41157203  0.06996948  2.14622611  1.8217317   4.29591723  2.45076112\n",
      "  -0.63614187 -1.91125437  4.94259785  2.30714669 -2.39602395  4.63460325\n",
      "  -3.05933115 -2.51371899 -4.71726272  2.55024272  3.42703614  4.7868769\n",
      "   4.21201842 -3.5424867  -4.50429917 -0.48099319  0.1316062   4.24485554\n",
      "   4.7728776   1.38593473 -4.99300561  0.74922867  3.95908786  2.79126176\n",
      "   3.99975326  4.84343426 -2.07181554  3.98489739  1.19557716 -1.65011212\n",
      "   2.41928082 -4.7743059  -2.80624142  2.12898243  4.66082827 -3.45711962\n",
      "   3.31431908 -4.59174474 -0.0981666   4.70477382 -4.95014286  2.87792284\n",
      "  -2.45991397  0.12189604  2.88425693 -1.36533547 -1.58816079 -4.39826434\n",
      "  -4.8054921   0.56007872 -3.78564008  2.50915003  3.30404243]]\n",
      "('Tolerance=', 4972171.1853834139)\n",
      "('error=', 99.501828333603413)\n"
     ]
    }
   ],
   "source": [
    "### Without Armijo Rule\n",
    "\n",
    "(a,b)=X.shape\n",
    "beta_lsg=np.zeros(b) #initial value for beta\n",
    "alpha= 0.0000001\n",
    "n_iter=100000 #maximim nunber iteration\n",
    "OF_iter=np.zeros(n_iter)\n",
    "tol_iter=np.zeros(n_iter)\n",
    "alpha_iter=np.zeros(n_iter)\n",
    "i=0;\n",
    "tol=1000; # Tolerance\n",
    "epsilon=1e-3;\n",
    "\n",
    "time_start = time.clock()\n",
    "while (i <= n_iter-2) and (tol>epsilon):\n",
    "    i=i+1\n",
    "    grad=least_sq_reg_der(beta_lsg,X,Y)\n",
    "    hess=least_sq_reg_hess(beta_lsg,X,Y) #this function gives us the value of the hessian\n",
    "    ddirect=-(np.dot(np.linalg.inv(hess), grad))\n",
    "    beta_lsg=beta_lsg+alpha*ddirect\n",
    "    OF_iter[i]=least_sq_reg(beta_lsg,X,Y) \n",
    "    tol=np.linalg.norm(hess,ord=2)\n",
    "    tol_iter[i]=tol\n",
    "    \n",
    "time_elapsed = (time.clock() - time_start) \n",
    "print('time elapsed=',time_elapsed)\n",
    "print('iterations',i)\n",
    "print(OF_iter[i])\n",
    "print(beta_lsg)\n",
    "print(np.transpose(beta_ls_exact))\n",
    "print('Tolerance=',tol)\n",
    "print('error=',np.linalg.norm(np.transpose(beta_ls_exact)-beta_lsg,ord=2)/np.linalg.norm(beta_lsg,ord=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii) Quasi-Newton method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('time elapsed=', 0.0035460236395010725)\n",
      "('iterations', 2)\n",
      "84919.4337684\n",
      "[-2.82009166  2.18757262 -3.33272408  2.40050035 -2.91964431  2.00327309\n",
      " -2.92131935  0.38737545  1.41670728  3.80403217 -3.04939149 -0.58693972\n",
      "  4.13024247  3.27121943  4.06064646  1.86865365  2.9009471   5.1028255\n",
      "  4.75282718 -2.37740208 -2.74905513 -3.94539386 -2.45767779  4.49870622\n",
      " -4.74962366  4.55818668  4.65647563 -0.59536061 -4.19274504  1.24511478\n",
      " -3.8973661  -1.04011885 -0.26481368 -2.28654173  2.16800687  4.92252054\n",
      "  2.94043056  0.5333243   4.79756441  0.43627901 -0.86060974  3.35301358\n",
      " -1.41157203  0.06996948  2.14622611  1.8217317   4.29591723  2.45076112\n",
      " -0.63614187 -1.91125437  4.94259785  2.30714669 -2.39602395  4.63460325\n",
      " -3.05933115 -2.51371899 -4.71726272  2.55024272  3.42703614  4.7868769\n",
      "  4.21201842 -3.5424867  -4.50429917 -0.48099319  0.1316062   4.24485554\n",
      "  4.7728776   1.38593473 -4.99300561  0.74922867  3.95908786  2.79126176\n",
      "  3.99975326  4.84343426 -2.07181554  3.98489739  1.19557716 -1.65011212\n",
      "  2.41928082 -4.7743059  -2.80624142  2.12898243  4.66082827 -3.45711962\n",
      "  3.31431908 -4.59174474 -0.0981666   4.70477382 -4.95014286  2.87792284\n",
      " -2.45991397  0.12189604  2.88425693 -1.36533547 -1.58816079 -4.39826434\n",
      " -4.8054921   0.56007872 -3.78564008  2.50915003  3.30404243]\n",
      "[[-2.82009166  2.18757262 -3.33272408  2.40050035 -2.91964431  2.00327309\n",
      "  -2.92131935  0.38737545  1.41670728  3.80403217 -3.04939149 -0.58693972\n",
      "   4.13024247  3.27121943  4.06064646  1.86865365  2.9009471   5.1028255\n",
      "   4.75282718 -2.37740208 -2.74905513 -3.94539386 -2.45767779  4.49870622\n",
      "  -4.74962366  4.55818668  4.65647563 -0.59536061 -4.19274504  1.24511478\n",
      "  -3.8973661  -1.04011885 -0.26481368 -2.28654173  2.16800687  4.92252054\n",
      "   2.94043056  0.5333243   4.79756441  0.43627901 -0.86060974  3.35301358\n",
      "  -1.41157203  0.06996948  2.14622611  1.8217317   4.29591723  2.45076112\n",
      "  -0.63614187 -1.91125437  4.94259785  2.30714669 -2.39602395  4.63460325\n",
      "  -3.05933115 -2.51371899 -4.71726272  2.55024272  3.42703614  4.7868769\n",
      "   4.21201842 -3.5424867  -4.50429917 -0.48099319  0.1316062   4.24485554\n",
      "   4.7728776   1.38593473 -4.99300561  0.74922867  3.95908786  2.79126176\n",
      "   3.99975326  4.84343426 -2.07181554  3.98489739  1.19557716 -1.65011212\n",
      "   2.41928082 -4.7743059  -2.80624142  2.12898243  4.66082827 -3.45711962\n",
      "   3.31431908 -4.59174474 -0.0981666   4.70477382 -4.95014286  2.87792284\n",
      "  -2.45991397  0.12189604  2.88425693 -1.36533547 -1.58816079 -4.39826434\n",
      "  -4.8054921   0.56007872 -3.78564008  2.50915003  3.30404243]]\n",
      "('Tolerance=', 2.987721920840585e-06)\n",
      "('error=', 6.429578978306502e-13)\n"
     ]
    }
   ],
   "source": [
    "### With Armijo Rule\n",
    "\n",
    "\n",
    "(a,b)=X.shape\n",
    "beta_quasi=np.zeros(b) #initial value for beta\n",
    "#alpha= 0.0000001\n",
    "n_iter=100000 #maximim nunber iteration\n",
    "OF_iter=np.zeros(n_iter)\n",
    "tol_iter=np.zeros(n_iter)\n",
    "alpha_iter=np.zeros(n_iter)\n",
    "i=0;\n",
    "tol=1000; # Tolerance\n",
    "epsilon=1e-5;\n",
    "\n",
    "\n",
    "\n",
    "time_start = time.clock()\n",
    "while (i <= n_iter-2) and (tol>epsilon):\n",
    "    i=i+1\n",
    "    grad=least_sq_reg_der(beta_quasi,X,Y)\n",
    "    if (i==1):\n",
    "        grad=least_sq_reg_der(beta_quasi,X,Y)\n",
    "        B=least_sq_reg_hess(beta_quasi,X,Y)\n",
    "    else:\n",
    "        grad_previous=grad\n",
    "        grad=least_sq_reg_der(beta_quasi,X,Y)\n",
    "        y= grad - grad_previous\n",
    "        s= beta_quasi - beta_quasi_previous\n",
    "        \n",
    "        a=np.dot(B, s)\n",
    "        b=np.transpose(np.dot(B, s))\n",
    "        c=np.dot(np.dot(np.transpose(s), B), s)\n",
    "        d=np.dot(y, np.transpose(y))\n",
    "        e=np.dot(np.transpose(y), s)\n",
    "        \n",
    "        ### Page 44 Formulas\n",
    "        B= B + np.dot(y-a, np.transpose(y-a))/np.dot(np.transpose(y-a),s)   # (Symmetric Rank-0ne)\n",
    "        # B= B - (np.dot(a,b)/c)+(d/e)   (BFGS Formula)\n",
    "    ddirect=-(np.dot(np.linalg.inv(B), grad))\n",
    " \n",
    "    ########################\n",
    "    #     Armijo Rule\n",
    "    sigma=0.1\n",
    "    beta=0.5\n",
    "    alpha=1\n",
    "    while (least_sq_reg(beta_quasi+alpha*ddirect,X,Y)> least_sq_reg(beta_quasi,X,Y)+alpha*sigma*np.dot(grad,ddirect)):\n",
    "        alpha=alpha*beta\n",
    "    ########################\n",
    "    beta_quasi_previous= beta_quasi\n",
    "    beta_quasi=beta_quasi_previous + alpha*ddirect\n",
    "    OF_iter[i]=least_sq_reg(beta_quasi,X,Y) \n",
    "    tol=np.linalg.norm(grad,ord=2)\n",
    "    tol_iter[i]=tol\n",
    "    \n",
    "time_elapsed = (time.clock() - time_start) \n",
    "print('time elapsed=',time_elapsed)\n",
    "print('iterations',i)\n",
    "print(OF_iter[i])\n",
    "print(beta_quasi)\n",
    "print(np.transpose(beta_ls_exact))\n",
    "print('Tolerance=',tol)\n",
    "print('error=',np.linalg.norm(np.transpose(beta_ls_exact)-beta_quasi,ord=2)/np.linalg.norm(beta_quasi,ord=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('time elapsed=', 77.44199172950175)\n",
      "('iterations', 99999)\n",
      "84612255.8376\n",
      "[-0.69455439  0.02330877 -0.03196133  0.02538503 -0.02802235  0.02159238\n",
      " -0.02782555  0.00498215  0.01533958  0.03817249 -0.0292014  -0.00445133\n",
      "  0.04292589  0.03425616  0.04192465  0.01969262  0.03000818  0.05220902\n",
      "  0.04888016 -0.02244421 -0.02604743 -0.0385179  -0.02231664  0.04574423\n",
      " -0.04602987  0.04638269  0.04767248 -0.00495406 -0.04085386  0.01351047\n",
      " -0.03731758 -0.00940024 -0.00109407 -0.02037651  0.02295996  0.05064143\n",
      "  0.03090196  0.00648642  0.04892168  0.0052158  -0.00708273  0.03500935\n",
      " -0.01268554  0.00202509  0.02323332  0.01934208  0.04378862  0.02574653\n",
      " -0.00521638 -0.01736145  0.05041185  0.02412116 -0.02206341  0.04692197\n",
      " -0.02956954 -0.0241941  -0.0450268   0.02771753  0.03523912  0.04909869\n",
      "  0.04288969 -0.03328658 -0.04322499 -0.00332134  0.00306589  0.04330142\n",
      "  0.04908182  0.01516352 -0.04848864  0.00754634  0.04075071  0.02911294\n",
      "  0.04070567  0.04907051 -0.01998648  0.04099637  0.01332996 -0.01517363\n",
      "  0.0248067  -0.04697969 -0.02677797  0.02275512  0.04800963 -0.03300447\n",
      "  0.0343062  -0.04535301  0.00093947  0.04869848 -0.04790353  0.02933167\n",
      " -0.02343911  0.00257443  0.03050908 -0.0114265  -0.0137986  -0.04242246\n",
      " -0.04702582  0.00790206 -0.03604466  0.02715162  0.03446269]\n",
      "[[-2.82009166  2.18757262 -3.33272408  2.40050035 -2.91964431  2.00327309\n",
      "  -2.92131935  0.38737545  1.41670728  3.80403217 -3.04939149 -0.58693972\n",
      "   4.13024247  3.27121943  4.06064646  1.86865365  2.9009471   5.1028255\n",
      "   4.75282718 -2.37740208 -2.74905513 -3.94539386 -2.45767779  4.49870622\n",
      "  -4.74962366  4.55818668  4.65647563 -0.59536061 -4.19274504  1.24511478\n",
      "  -3.8973661  -1.04011885 -0.26481368 -2.28654173  2.16800687  4.92252054\n",
      "   2.94043056  0.5333243   4.79756441  0.43627901 -0.86060974  3.35301358\n",
      "  -1.41157203  0.06996948  2.14622611  1.8217317   4.29591723  2.45076112\n",
      "  -0.63614187 -1.91125437  4.94259785  2.30714669 -2.39602395  4.63460325\n",
      "  -3.05933115 -2.51371899 -4.71726272  2.55024272  3.42703614  4.7868769\n",
      "   4.21201842 -3.5424867  -4.50429917 -0.48099319  0.1316062   4.24485554\n",
      "   4.7728776   1.38593473 -4.99300561  0.74922867  3.95908786  2.79126176\n",
      "   3.99975326  4.84343426 -2.07181554  3.98489739  1.19557716 -1.65011212\n",
      "   2.41928082 -4.7743059  -2.80624142  2.12898243  4.66082827 -3.45711962\n",
      "   3.31431908 -4.59174474 -0.0981666   4.70477382 -4.95014286  2.87792284\n",
      "  -2.45991397  0.12189604  2.88425693 -1.36533547 -1.58816079 -4.39826434\n",
      "  -4.8054921   0.56007872 -3.78564008  2.50915003  3.30404243]]\n",
      "('Tolerance=', 27512897.560719263)\n",
      "('error=', 41.810947541672022)\n"
     ]
    }
   ],
   "source": [
    "### Without Armijo Rule\n",
    "\n",
    "\n",
    "(a,b)=X.shape\n",
    "beta_quasi=np.zeros(b) #initial value for beta\n",
    "alpha= 0.0000001\n",
    "n_iter=100000 #maximim nunber iteration\n",
    "OF_iter=np.zeros(n_iter)\n",
    "tol_iter=np.zeros(n_iter)\n",
    "alpha_iter=np.zeros(n_iter)\n",
    "i=0;\n",
    "tol=1000; # Tolerance\n",
    "epsilon=1e-5;\n",
    "\n",
    "\n",
    "\n",
    "time_start = time.clock()\n",
    "while (i <= n_iter-2) and (tol>epsilon):\n",
    "    i=i+1\n",
    "    grad=least_sq_reg_der(beta_quasi,X,Y)\n",
    "    if (i==1):\n",
    "        grad=least_sq_reg_der(beta_quasi,X,Y)\n",
    "        B=least_sq_reg_hess(beta_quasi,X,Y)\n",
    "    else:\n",
    "        grad_previous=grad\n",
    "        grad=least_sq_reg_der(beta_quasi,X,Y)\n",
    "        y= grad - grad_previous\n",
    "        s= beta_quasi - beta_quasi_previous\n",
    "        \n",
    "        a=np.dot(B, s)\n",
    "        b=np.transpose(np.dot(B, s))\n",
    "        c=np.dot(np.dot(np.transpose(s), B), s)\n",
    "        d=np.dot(y, np.transpose(y))\n",
    "        e=np.dot(np.transpose(y), s)\n",
    "        \n",
    "        ### Page 44 Formulas\n",
    "        \n",
    "        B= B + np.dot(y-a, np.transpose(y-a))/np.dot(np.transpose(y-a),s)   # (Symmetric Rank-0ne)\n",
    "        \n",
    "        # B= B - (np.dot(a,b)/c)+(d/e)   (BFGS Formula)\n",
    "    ddirect=-(np.dot(np.linalg.inv(B), grad))\n",
    "    \n",
    "    beta_quasi_previous= beta_quasi\n",
    "    beta_quasi=beta_quasi_previous + alpha*ddirect\n",
    "    OF_iter[i]=least_sq_reg(beta_quasi,X,Y) \n",
    "    tol=np.linalg.norm(grad,ord=2)\n",
    "    tol_iter[i]=tol\n",
    "    \n",
    "time_elapsed = (time.clock() - time_start) \n",
    "print('time elapsed=',time_elapsed)\n",
    "print('iterations',i)\n",
    "print(OF_iter[i])\n",
    "print(beta_quasi)\n",
    "print(np.transpose(beta_ls_exact))\n",
    "print('Tolerance=',tol)\n",
    "print('error=',np.linalg.norm(np.transpose(beta_ls_exact)-beta_quasi,ord=2)/np.linalg.norm(beta_quasi,ord=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time elapsed</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Tolerance</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient method (Armijo Rule)</th>\n",
       "      <td>215.5700</td>\n",
       "      <td>99999</td>\n",
       "      <td>1.196000e+01</td>\n",
       "      <td>5.617000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient method</th>\n",
       "      <td>14.0900</td>\n",
       "      <td>99999</td>\n",
       "      <td>1.664000e+01</td>\n",
       "      <td>8.595000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Newton method (Armijo Rule)</th>\n",
       "      <td>293.5500</td>\n",
       "      <td>99999</td>\n",
       "      <td>4.972171e+06</td>\n",
       "      <td>4.240000e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Newton method</th>\n",
       "      <td>192.1500</td>\n",
       "      <td>99999</td>\n",
       "      <td>4.972171e+06</td>\n",
       "      <td>9.915000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quasi Newton method (Armijo Rule)</th>\n",
       "      <td>0.0035</td>\n",
       "      <td>2</td>\n",
       "      <td>2.990000e-06</td>\n",
       "      <td>6.430000e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quasi Newton method</th>\n",
       "      <td>77.4400</td>\n",
       "      <td>99999</td>\n",
       "      <td>2.751290e+07</td>\n",
       "      <td>4.181000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Time elapsed  Iteration     Tolerance  \\\n",
       "Gradient method (Armijo Rule)          215.5700      99999  1.196000e+01   \n",
       "Gradient method                         14.0900      99999  1.664000e+01   \n",
       "Newton method (Armijo Rule)            293.5500      99999  4.972171e+06   \n",
       "Newton method                          192.1500      99999  4.972171e+06   \n",
       "Quasi Newton method (Armijo Rule)        0.0035          2  2.990000e-06   \n",
       "Quasi Newton method                     77.4400      99999  2.751290e+07   \n",
       "\n",
       "                                          Error  \n",
       "Gradient method (Armijo Rule)      5.617000e-02  \n",
       "Gradient method                    8.595000e-02  \n",
       "Newton method (Armijo Rule)        4.240000e-12  \n",
       "Newton method                      9.915000e+01  \n",
       "Quasi Newton method (Armijo Rule)  6.430000e-13  \n",
       "Quasi Newton method                4.181000e+01  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sympy\n",
    "from pandas import DataFrame\n",
    "from sympy import *\n",
    "\n",
    "# For Final report we need to put 'Time elapsed', 'Iteration','Tolerance', 'Error'\n",
    "### Fill value instead of 1 2 3 .....\n",
    "t = [[215.57 ,99999 ,11.96 ,0.05617 ], #Gradient method (Armijo Rule)\n",
    "     [14.09 ,99999 ,16.64 ,0.08595 ], #Gradient method\n",
    "     [293.55 ,99999 ,4972171.18 ,4.24e-12 ], #Newton method (Armijo Rule)\n",
    "     [192.15 ,99999 ,4972171.18 ,99.15 ], #Newton method\n",
    "     [0.0035 ,2 ,2.99e-6 ,6.43e-13 ], #Quasi Newton method (Armijo Rule)\n",
    "     [77.44 ,99999 ,27512897.56 ,41.81 ]] #Quasi Newton method\n",
    "\n",
    "\n",
    "\n",
    "table = DataFrame(t, index=['Gradient method (Armijo Rule)', 'Gradient method', 'Newton method (Armijo Rule)' , 'Newton method', 'Quasi Newton method (Armijo Rule)', 'Quasi Newton method'],\n",
    "                  columns=['Time elapsed', 'Iteration', 'Tolerance', 'Error'])\n",
    "table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## E)\n",
    "Estimate the value of the regression coefficients y implementing the coordinate gradient method and\n",
    "the stochastic gradient method. Compare their performance with the algorithms in c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#definition of partial gradient \n",
    "def least_sq_reg_der_par(beta_ls,X,Y,i):\n",
    "    beta_ls=np.matrix(beta_ls)\n",
    "    pp=-2*(Y[i]-X[i,]*np.transpose(beta_ls))*X[i,]\n",
    "    aa= np.squeeze(np.asarray(pp))\n",
    "    return aa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinate gradient   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('time elapsed=', 163.64487752970308)\n",
      "('iterations', 99999)\n",
      "84919.7410451\n",
      "[-2.50021396  2.18682373 -3.33330932  2.39975782 -2.92014081  2.00246299\n",
      " -2.92190745  0.38682466  1.41610014  3.80388697 -3.04994025 -0.58761597\n",
      "  4.12933115  3.27038748  4.05991182  1.86812078  2.90038461  5.10213145\n",
      "  4.7520726  -2.37795869 -2.74969627 -3.94575757 -2.45870403  4.49820917\n",
      " -4.75009063  4.55768429  4.65587883 -0.59582511 -4.19314339  1.24460461\n",
      " -3.89808893 -1.04057926 -0.26554226 -2.28768565  2.16739383  4.92170907\n",
      "  2.93963913  0.53277756  4.79699291  0.43585696 -0.86131784  3.3522031\n",
      " -1.41222325  0.06931246  2.14531845  1.82115116  4.29541405  2.45009805\n",
      " -0.63666568 -1.91204923  4.94201387  2.30657644 -2.39688656  4.63435576\n",
      " -3.05973144 -2.51412631 -4.71816209  2.54908238  3.42649047  4.78616836\n",
      "  4.2115354  -3.54344122 -4.50507367 -0.48169823  0.13078017  4.24435255\n",
      "  4.7720993   1.38526205 -4.99358747  0.74918188  3.95849775  2.79061004\n",
      "  3.99931219  4.84301543 -2.07213891  3.98423849  1.19489186 -1.65072046\n",
      "  2.41891899 -4.77456556 -2.80681004  2.1282199   4.66004788 -3.45777118\n",
      "  3.31367115 -4.59191388 -0.09910009  4.70386052 -4.95080481  2.87758379\n",
      " -2.46041758  0.12123455  2.88339249 -1.36639218 -1.58913823 -4.39890042\n",
      " -4.80587062  0.55896863 -3.78642918  2.50807425  3.30328032]\n",
      "[[-2.82009166  2.18757262 -3.33272408  2.40050035 -2.91964431  2.00327309\n",
      "  -2.92131935  0.38737545  1.41670728  3.80403217 -3.04939149 -0.58693972\n",
      "   4.13024247  3.27121943  4.06064646  1.86865365  2.9009471   5.1028255\n",
      "   4.75282718 -2.37740208 -2.74905513 -3.94539386 -2.45767779  4.49870622\n",
      "  -4.74962366  4.55818668  4.65647563 -0.59536061 -4.19274504  1.24511478\n",
      "  -3.8973661  -1.04011885 -0.26481368 -2.28654173  2.16800687  4.92252054\n",
      "   2.94043056  0.5333243   4.79756441  0.43627901 -0.86060974  3.35301358\n",
      "  -1.41157203  0.06996948  2.14622611  1.8217317   4.29591723  2.45076112\n",
      "  -0.63614187 -1.91125437  4.94259785  2.30714669 -2.39602395  4.63460325\n",
      "  -3.05933115 -2.51371899 -4.71726272  2.55024272  3.42703614  4.7868769\n",
      "   4.21201842 -3.5424867  -4.50429917 -0.48099319  0.1316062   4.24485554\n",
      "   4.7728776   1.38593473 -4.99300561  0.74922867  3.95908786  2.79126176\n",
      "   3.99975326  4.84343426 -2.07181554  3.98489739  1.19557716 -1.65011212\n",
      "   2.41928082 -4.7743059  -2.80624142  2.12898243  4.66082827 -3.45711962\n",
      "   3.31431908 -4.59174474 -0.0981666   4.70477382 -4.95014286  2.87792284\n",
      "  -2.45991397  0.12189604  2.88425693 -1.36533547 -1.58816079 -4.39826434\n",
      "  -4.8054921   0.56007872 -3.78564008  2.50915003  3.30404243]]\n",
      "('Tolerance=', 4.4303189821277034)\n",
      "('error=', 0.0098751677873833519)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "(a,b)=X.shape\n",
    "#alpha= 0.0000001\n",
    "beta_coor=np.zeros(b) #initial value for beta\n",
    "n_iter=100000 #maximim nunber iteration\n",
    "OF_iter=np.zeros(n_iter)\n",
    "tol_iter=np.zeros(n_iter)\n",
    "alpha_iter=np.zeros(n_iter)\n",
    "i=0;\n",
    "tol=1000;\n",
    "epsilon=1e-3;\n",
    "\n",
    "time_start = time.clock()\n",
    "while (i <= n_iter-2) and (tol>epsilon):\n",
    "    i=i+1\n",
    "    grad = least_sq_reg_der(beta_coor,X,Y)\n",
    "    ddirect =np.zeros(b)\n",
    "    j = random.randint(0, b-1)\n",
    "    ddirect[j] = - grad[j]\n",
    "    ###################################\n",
    "    #      Armijo Rule-----Choose an appropiate alpha\n",
    "    sigma = 0.1\n",
    "    beta = 0.5\n",
    "    alpha = 1\n",
    "    while (least_sq_reg(beta_coor + alpha*ddirect , X, Y)> least_sq_reg(beta_coor, X, Y) + alpha*sigma*np.dot(grad,ddirect)):\n",
    "          alpha = alpha*beta\n",
    "    ###################################\n",
    "    beta_coor = beta_coor + alpha*ddirect\n",
    "    OF_iter[i] = least_sq_reg(beta_coor, X, Y)\n",
    "    tol = np.linalg.norm(grad,ord=2)\n",
    "    tol_iter[i] = tol\n",
    "    alpha_iter[i] = alpha\n",
    "\n",
    "time_elapsed = (time.clock() - time_start) \n",
    "print('time elapsed=',time_elapsed)\n",
    "print('iterations',i)\n",
    "print(OF_iter[i])\n",
    "print(beta_coor)\n",
    "print(np.transpose(beta_ls_exact))\n",
    "print('Tolerance=',tol)\n",
    "print('error=',np.linalg.norm(np.transpose(beta_ls_exact)-beta_coor,ord=2)/np.linalg.norm(beta_coor,ord=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic gradient  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('time elapsed=', 322.0782561465603)\n",
      "('iterations', 99999)\n",
      "2113446.74323\n",
      "[ 0.10969587  2.15459106 -2.73794796  2.43062366 -1.81939819  1.55858974\n",
      " -2.06132185  1.17113482  0.49903371  1.57226603 -0.64545193 -0.10494674\n",
      "  5.42318687  1.38397385  2.23523869  2.42252443  2.59244987  3.03017531\n",
      "  4.35250852 -0.45845149 -2.30684351 -3.81494188 -1.9625614   2.64530825\n",
      " -2.50652389  4.22243716  3.39618464  1.15481196 -3.14793245  2.51914073\n",
      " -1.94143724 -0.90108007 -0.03820853 -1.42390156  2.09482173  1.95039804\n",
      " -1.77012151  1.55584506  2.69934517  1.4177997  -1.7876631   1.38743046\n",
      " -0.57572693  2.07897314  0.04608848  0.83539717  4.01770176  1.29246787\n",
      " -0.06485886 -1.26403007  3.41106878  1.65507843 -1.80252834  3.02580618\n",
      " -1.95996077 -0.67287535 -3.8303346   1.53249861  2.95217127  3.50176353\n",
      "  3.30527248 -1.89845257 -1.97434118  0.15292702 -1.0444904   2.73142989\n",
      "  2.0422938   1.27693678 -3.35879968  1.12025885  2.81241255  0.76902383\n",
      "  2.01769281  0.77575851  1.53522836  2.43482166 -0.96953795 -1.15269728\n",
      "  2.71898709 -2.98207682 -1.19521613  0.38061522  2.15831357 -2.96984636\n",
      "  2.2403703  -0.82964194  1.08526317  4.11447167 -1.7634749   0.71495591\n",
      " -1.09210182  0.74986064  2.98311974  0.95349042  1.22215274 -1.3047014\n",
      " -4.55340843 -0.87160734 -2.48210947  3.10061311  2.04836621]\n",
      "[[-2.82009166  2.18757262 -3.33272408  2.40050035 -2.91964431  2.00327309\n",
      "  -2.92131935  0.38737545  1.41670728  3.80403217 -3.04939149 -0.58693972\n",
      "   4.13024247  3.27121943  4.06064646  1.86865365  2.9009471   5.1028255\n",
      "   4.75282718 -2.37740208 -2.74905513 -3.94539386 -2.45767779  4.49870622\n",
      "  -4.74962366  4.55818668  4.65647563 -0.59536061 -4.19274504  1.24511478\n",
      "  -3.8973661  -1.04011885 -0.26481368 -2.28654173  2.16800687  4.92252054\n",
      "   2.94043056  0.5333243   4.79756441  0.43627901 -0.86060974  3.35301358\n",
      "  -1.41157203  0.06996948  2.14622611  1.8217317   4.29591723  2.45076112\n",
      "  -0.63614187 -1.91125437  4.94259785  2.30714669 -2.39602395  4.63460325\n",
      "  -3.05933115 -2.51371899 -4.71726272  2.55024272  3.42703614  4.7868769\n",
      "   4.21201842 -3.5424867  -4.50429917 -0.48099319  0.1316062   4.24485554\n",
      "   4.7728776   1.38593473 -4.99300561  0.74922867  3.95908786  2.79126176\n",
      "   3.99975326  4.84343426 -2.07181554  3.98489739  1.19557716 -1.65011212\n",
      "   2.41928082 -4.7743059  -2.80624142  2.12898243  4.66082827 -3.45711962\n",
      "   3.31431908 -4.59174474 -0.0981666   4.70477382 -4.95014286  2.87792284\n",
      "  -2.45991397  0.12189604  2.88425693 -1.36533547 -1.58816079 -4.39826434\n",
      "  -4.8054921   0.56007872 -3.78564008  2.50915003  3.30404243]]\n",
      "('Tolerance=', 259606.19719997552)\n",
      "('error=', 0.74201546127562212)\n"
     ]
    }
   ],
   "source": [
    "(a,b)=X.shape\n",
    "#alpha= 0.0000001\n",
    "beta_sto=np.zeros(b) #initial value for beta\n",
    "n_iter=100000 #maximum nunber iteration\n",
    "OF_iter=np.zeros(n_iter)\n",
    "tol_iter=np.zeros(n_iter)\n",
    "alpha_iter=np.zeros(n_iter)\n",
    "i=0;\n",
    "tol=1000;\n",
    "epsilon=1e-3;\n",
    "\n",
    "time_start = time.clock()\n",
    "while (i <= n_iter-2) and (tol>epsilon):\n",
    "    i=i+1\n",
    "    j = random.randint(0, b-1)\n",
    "    grad_par = least_sq_reg_der_par(beta_sto,X,Y,j)\n",
    "    grad = least_sq_reg_der(beta_sto,X,Y)\n",
    "    ddirect = - grad_par\n",
    "    ###################################\n",
    "    #      Armijo Rule-----Choose an appropiate alpha\n",
    "    sigma = 0.1\n",
    "    beta = 0.5\n",
    "    alpha = 1\n",
    "    while (least_sq_reg(beta_sto + alpha*ddirect , X, Y)> least_sq_reg(beta_sto, X, Y) + alpha*sigma*np.dot(grad,ddirect)):\n",
    "           alpha = alpha*beta\n",
    "    ###################################\n",
    "    beta_sto = beta_sto + ddirect*alpha\n",
    "    OF_iter[i] = least_sq_reg(beta_sto, X, Y)\n",
    "    tol = np.linalg.norm(grad,ord=2)\n",
    "    tol_iter[i] = tol\n",
    "    alpha_iter[i] = alpha\n",
    "\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print('time elapsed=',time_elapsed)\n",
    "print('iterations',i)\n",
    "print(OF_iter[i])\n",
    "print(beta_sto)\n",
    "print(np.transpose(beta_ls_exact))\n",
    "print('Tolerance=',tol)\n",
    "print('error=',np.linalg.norm(np.transpose(beta_ls_exact)-beta_sto,ord=2)/np.linalg.norm(beta_sto,ord=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time elapsed</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Tolerance</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Coordinate gradient</th>\n",
       "      <td>163.64</td>\n",
       "      <td>99999</td>\n",
       "      <td>4.43</td>\n",
       "      <td>0.0099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stochastic gradient</th>\n",
       "      <td>322.08</td>\n",
       "      <td>99999</td>\n",
       "      <td>259606.20</td>\n",
       "      <td>0.7420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Time elapsed  Iteration  Tolerance   Error\n",
       "Coordinate gradient        163.64      99999       4.43  0.0099\n",
       "Stochastic gradient        322.08      99999  259606.20  0.7420"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sympy\n",
    "from pandas import DataFrame\n",
    "from sympy import *\n",
    "\n",
    "# For Final report we need to put 'Time elapsed', 'Iteration','Tolerance', 'Error'\n",
    "### Fill value instead of 1 2 3 .....\n",
    "t = [[163.64 ,99999 ,4.43 ,0.0099 ], #Coordinate gradient\n",
    "     [322.08 ,99999 ,259606.20 ,0.7420 ]] #Stochastic gradient\n",
    "\n",
    "\n",
    "table = DataFrame(t, index=['Coordinate gradient', 'Stochastic gradient'], columns=['Time elapsed', 'Iteration',\n",
    "                                                                                    'Tolerance', 'Error'])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
