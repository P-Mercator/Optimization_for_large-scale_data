{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Members\n",
    "Pierre Mercatoris – Pablo Bordons Estrada - Sergio Gámez Ruiz de Olano – Mohammadmehdi\n",
    "Fayazbakhsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.05690932]\n",
      " [ 2.15828544]\n",
      " [-0.29490484]\n",
      " [-1.34581168]\n",
      " [ 2.20117406]\n",
      " [ 0.42397514]\n",
      " [-0.82398851]\n",
      " [ 1.81364924]\n",
      " [ 0.86747039]\n",
      " [-2.34873849]\n",
      " [-3.12359089]\n",
      " [ 0.77057558]\n",
      " [-2.1589737 ]\n",
      " [-1.38827103]\n",
      " [ 4.07756484]\n",
      " [ 0.47152892]\n",
      " [ 4.84450501]\n",
      " [-1.59458199]\n",
      " [-2.22242756]\n",
      " [-2.45162542]\n",
      " [ 4.72223683]\n",
      " [-2.59559141]\n",
      " [ 3.52338894]\n",
      " [ 0.42372921]\n",
      " [-4.39296816]\n",
      " [ 4.9300793 ]\n",
      " [ 3.28390125]\n",
      " [-3.48180498]\n",
      " [ 0.4424662 ]\n",
      " [-1.55505248]\n",
      " [ 0.79581748]\n",
      " [-2.39816166]\n",
      " [ 4.56861057]\n",
      " [ 3.43376717]\n",
      " [-0.40535386]\n",
      " [-4.93319533]\n",
      " [-3.04623369]\n",
      " [ 3.43226599]\n",
      " [ 4.08190336]\n",
      " [ 3.12074063]\n",
      " [ 2.46781386]\n",
      " [ 4.03163691]\n",
      " [ 0.81221959]\n",
      " [-2.75377155]\n",
      " [ 1.46057359]\n",
      " [ 2.71381628]\n",
      " [-0.2182772 ]\n",
      " [-3.74828416]\n",
      " [ 0.77882295]\n",
      " [-1.52293682]\n",
      " [-1.0528976 ]\n",
      " [ 3.46469324]\n",
      " [ 1.17731988]\n",
      " [-1.44375179]\n",
      " [ 1.86703311]\n",
      " [ 1.16419156]\n",
      " [-0.65375555]\n",
      " [ 3.36138624]\n",
      " [-4.78147052]\n",
      " [ 3.77156093]\n",
      " [-4.47780241]\n",
      " [-1.20691726]\n",
      " [-3.03328124]\n",
      " [-0.81653562]\n",
      " [-2.77165264]\n",
      " [-0.97350498]\n",
      " [-3.88910101]\n",
      " [-2.20205481]\n",
      " [ 2.87254992]\n",
      " [-0.40393351]\n",
      " [-3.75275908]\n",
      " [ 3.12926678]\n",
      " [-0.38616914]\n",
      " [ 3.82482815]\n",
      " [ 3.30080929]\n",
      " [-3.67566535]\n",
      " [ 3.86290472]\n",
      " [-1.1075488 ]\n",
      " [-0.22799475]\n",
      " [ 3.97681805]\n",
      " [-0.45731927]\n",
      " [-2.9057709 ]\n",
      " [ 0.70887173]\n",
      " [-0.09446292]\n",
      " [ 2.65234334]\n",
      " [-1.17024659]\n",
      " [ 1.88194184]\n",
      " [-1.18405204]\n",
      " [-3.21520167]\n",
      " [ 4.25898672]\n",
      " [-2.50945054]\n",
      " [ 4.05653738]\n",
      " [ 4.63392335]\n",
      " [ 0.21319767]\n",
      " [ 0.38476926]\n",
      " [ 3.34385796]\n",
      " [ 1.86774045]\n",
      " [-3.82905617]\n",
      " [ 2.67090277]\n",
      " [ 3.61475477]\n",
      " [-4.12378267]]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "nsample = 1000\n",
    "nvariables = 100\n",
    "X0=np.ones([nsample, 1])\n",
    "X1=np.random.uniform(0, 10, ([nsample,nvariables]))\n",
    "X=np.concatenate([X0, X1], axis=1)\n",
    "error=np.random.normal(0, 1, (nsample,1)) # Normal random error\n",
    "beta=np.random.uniform(-5, 5, size=([nvariables+1, 1]))\n",
    "Y=np.dot(X, beta)+error\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A)\n",
    "Estimate the value of the regression coefficients by using the analytical solution for the least squares\n",
    "estimation problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('time elapsed=', 0.0020424515823833644)\n",
      "[[-0.3312345 ]\n",
      " [ 2.16987542]\n",
      " [-0.28006731]\n",
      " [-1.31305434]\n",
      " [ 2.19739725]\n",
      " [ 0.44376467]\n",
      " [-0.80317061]\n",
      " [ 1.78171474]\n",
      " [ 0.86218419]\n",
      " [-2.35206709]\n",
      " [-3.12369441]\n",
      " [ 0.77103314]\n",
      " [-2.1632876 ]\n",
      " [-1.39316238]\n",
      " [ 4.07568713]\n",
      " [ 0.48383819]\n",
      " [ 4.84787724]\n",
      " [-1.60251216]\n",
      " [-2.20112221]\n",
      " [-2.44010841]\n",
      " [ 4.72084042]\n",
      " [-2.5988558 ]\n",
      " [ 3.51103899]\n",
      " [ 0.43600634]\n",
      " [-4.40913056]\n",
      " [ 4.92905925]\n",
      " [ 3.30386352]\n",
      " [-3.4871993 ]\n",
      " [ 0.43682339]\n",
      " [-1.54447007]\n",
      " [ 0.77569753]\n",
      " [-2.39747555]\n",
      " [ 4.57656095]\n",
      " [ 3.44596201]\n",
      " [-0.41281857]\n",
      " [-4.93252925]\n",
      " [-3.04748605]\n",
      " [ 3.43188028]\n",
      " [ 4.05860479]\n",
      " [ 3.12379721]\n",
      " [ 2.45743472]\n",
      " [ 4.03179014]\n",
      " [ 0.79943249]\n",
      " [-2.75591577]\n",
      " [ 1.47760098]\n",
      " [ 2.6972209 ]\n",
      " [-0.22030008]\n",
      " [-3.74281122]\n",
      " [ 0.76913766]\n",
      " [-1.51314453]\n",
      " [-1.06266655]\n",
      " [ 3.47974865]\n",
      " [ 1.17897966]\n",
      " [-1.43705443]\n",
      " [ 1.893623  ]\n",
      " [ 1.16010023]\n",
      " [-0.66102509]\n",
      " [ 3.3591382 ]\n",
      " [-4.78528607]\n",
      " [ 3.76512667]\n",
      " [-4.48112468]\n",
      " [-1.21357384]\n",
      " [-3.02453052]\n",
      " [-0.82846868]\n",
      " [-2.77684027]\n",
      " [-0.97692756]\n",
      " [-3.89957462]\n",
      " [-2.20120102]\n",
      " [ 2.88732849]\n",
      " [-0.3960742 ]\n",
      " [-3.75974143]\n",
      " [ 3.11944498]\n",
      " [-0.39365021]\n",
      " [ 3.81445564]\n",
      " [ 3.28626182]\n",
      " [-3.67363784]\n",
      " [ 3.87384819]\n",
      " [-1.11023846]\n",
      " [-0.22961582]\n",
      " [ 3.99721922]\n",
      " [-0.44087655]\n",
      " [-2.91951306]\n",
      " [ 0.71366585]\n",
      " [-0.08974121]\n",
      " [ 2.64416123]\n",
      " [-1.17109541]\n",
      " [ 1.88370953]\n",
      " [-1.19222121]\n",
      " [-3.21293198]\n",
      " [ 4.24293921]\n",
      " [-2.49130663]\n",
      " [ 4.06396557]\n",
      " [ 4.63353289]\n",
      " [ 0.22346533]\n",
      " [ 0.37789662]\n",
      " [ 3.34704356]\n",
      " [ 1.88712791]\n",
      " [-3.82574035]\n",
      " [ 2.68663013]\n",
      " [ 3.59618696]\n",
      " [-4.1194074 ]]\n"
     ]
    }
   ],
   "source": [
    "## a\n",
    "\n",
    "time_start = time.clock()\n",
    "beta_ls_exact=np.dot(np.dot(np.linalg.inv(np.dot(np.transpose(X),X)),np.transpose(X)),Y)\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print('time elapsed=',time_elapsed)\n",
    "print(beta_ls_exact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5263120378225907, 3.9156121236269756, 3.2635193896499768, 8.3142427303192932, 11.139360760558176, 2.60193068785295, 12.777884974957649, 15.529777222334781, 2.4679327030443652, 4.7200415767502459, 8.8779346441501001, 6.7144220174517226, 23.610962549133543, 11.68521014338045, 10.735864616795785, 8.0903777800296144, 5.4175998134987493, 10.166686468895984]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhoAAAGHCAYAAAD2qfsmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMVMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd2a6390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# b\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "lambda_est=[]\n",
    "sigma=np.arange(1,10, 0.5)\n",
    "\n",
    "for i in sigma :\n",
    "    error=np.random.normal(0, i, (nsample,1)) # Normal random error with different sigma\n",
    "    Y=np.dot(X, beta)+error\n",
    "    beta_ls_exact=np.dot(np.dot(np.linalg.inv(np.dot(np.transpose(X),X)),np.transpose(X)),Y)\n",
    "    lambda_est.append((np.linalg.norm(beta-beta_ls_exact,ord=2)/np.linalg.norm(beta,ord=2))*100)\n",
    "    \n",
    "print lambda_est\n",
    "\n",
    "\n",
    "plt.plot(lambda_est, 'bs')\n",
    "plt.xlabel('Sigma')\n",
    "plt.ylabel('Lambda')\n",
    "plt.title('Lambda Vs. Sigma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C)\n",
    "Estimate the value of the regression coefficients (least squares) by using the tool minimize from the\n",
    "python package Scipy.optimize. Try at least three available solvers and compare their performance\n",
    "(iterations, function, gradient and hessian evaluations as well as total computational time).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 80069.171195\n",
      "         Iterations: 15\n",
      "         Function evaluations: 18\n",
      "         Gradient evaluations: 32\n",
      "         Hessian evaluations: 15\n",
      "('time elapsed=', 0.020329796010628343)\n",
      "[ 2.52907023  2.42614164 -0.41632141 -1.40731497  2.17454426  0.18096219\n",
      " -0.86563098  1.82734867  0.8954817  -2.37274123 -2.98026418  0.86919563\n",
      " -2.12799    -1.33734538  3.96333728  0.39168058  4.90934384 -1.49930136\n",
      " -2.20653887 -2.4521232   4.54475819 -2.509499    3.44278426  0.40179246\n",
      " -4.20758     4.73542469  3.16544822 -3.38493409  0.40813378 -1.50592527\n",
      "  0.90518528 -2.54794857  4.62552053  3.52342176 -0.375623   -4.98891832\n",
      " -3.08688432  3.42572591  3.91629563  2.99467011  2.38395674  4.09115926\n",
      "  0.98062699 -2.74329505  1.54618301  2.57435891 -0.24873628 -3.87749783\n",
      "  0.81226377 -1.52292466 -1.01979152  3.44045897  1.17340441 -1.47480637\n",
      "  1.96311657  1.13023595 -0.79217391  3.49589603 -4.58586374  3.64191904\n",
      " -4.52272112 -1.31597929 -2.94847191 -0.95578945 -2.70604404 -0.93611108\n",
      " -3.94129487 -2.11542351  2.76069848 -0.36997347 -3.7984632   3.252003\n",
      " -0.21219904  3.88831056  3.40341    -3.28097547  3.97908088 -1.11943055\n",
      " -0.09233092  3.93858052 -0.30192807 -3.04076431  0.66607526 -0.18142424\n",
      "  2.5962986  -1.19740846  1.94104038 -1.19953445 -3.46219634  4.13250658\n",
      " -2.61965362  3.94746356  4.44984831  0.23877864  0.49978233  3.40173873\n",
      "  1.78805554 -3.71162523  2.52658804  3.51734131 -4.21154744]\n",
      "('error=', 4.6173191971965429e-06)\n"
     ]
    }
   ],
   "source": [
    "# c : Newton-CG\n",
    "\n",
    "def least_sq_reg_der(beta_ls,X,Y):\n",
    "    beta_ls=np.matrix(beta_ls)\n",
    "    pp=-2*np.dot(np.transpose(Y-np.dot(X,np.transpose(beta_ls))),X)\n",
    "    return np.squeeze(np.asarray(pp))\n",
    "        \n",
    "        \n",
    "def least_sq_reg_hess(beta_ls,X,Y):\n",
    "    return 2*np.dot(np.transpose(X),X)\n",
    "\n",
    "\n",
    "\n",
    "time_start = time.clock()\n",
    "#run your code\n",
    "                   \n",
    "res = minimize(least_sq_reg, beta_ls0, args=(X,Y), method = 'Newton-CG',jac=least_sq_reg_der, hess=least_sq_reg_hess, options = {'disp': True})\n",
    "time_elapsed = (time.clock() - time_start) \n",
    "print('time elapsed=',time_elapsed)\n",
    "print(res.x)\n",
    "np.linalg.inv(least_sq_reg_hess(res.x,X,Y))\n",
    "print('error=',np.linalg.norm(np.transpose(beta_ls_exact)-res.x,ord=2)/np.linalg.norm(np.transpose(beta_ls_exact),ord=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 80069.171181\n",
      "         Iterations: 124\n",
      "         Function evaluations: 23691\n",
      "         Gradient evaluations: 230\n",
      "('time elapsed=', 1.4183544163533952)\n",
      "[ 2.52919709  2.42614579 -0.4163286  -1.40731715  2.1745403   0.18095672\n",
      " -0.86562913  1.82734177  0.89547621 -2.37274956 -2.98026243  0.86919653\n",
      " -2.12799218 -1.33734602  3.96333955  0.39168156  4.90935211 -1.49929784\n",
      " -2.20653837 -2.45213604  4.54474867 -2.50949541  3.44278643  0.40178934\n",
      " -4.20757911  4.73542244  3.16545021 -3.38493125  0.40812188 -1.5059241\n",
      "  0.90518818 -2.54795349  4.62552112  3.52342335 -0.37562198 -4.98891744\n",
      " -3.08687982  3.42573121  3.91629758  2.99467647  2.38395901  4.09116047\n",
      "  0.98061959 -2.74329385  1.54618723  2.57436218 -0.248741   -3.87750168\n",
      "  0.81225978 -1.52292348 -1.01978847  3.44045308  1.17341042 -1.47481482\n",
      "  1.96312072  1.13022637 -0.79217751  3.49589995 -4.58586708  3.64192139\n",
      " -4.52271991 -1.31598103 -2.94847048 -0.95579513 -2.7060459  -0.93610872\n",
      " -3.94129548 -2.11541677  2.76068875 -0.36996399 -3.79846744  3.25200272\n",
      " -0.21219681  3.88830278  3.40341219 -3.28097665  3.97907491 -1.11942626\n",
      " -0.09232706  3.93859146 -0.30193416 -3.04075808  0.66607154 -0.18141887\n",
      "  2.59631263 -1.19741149  1.94104056 -1.19952072 -3.46220584  4.13251023\n",
      " -2.61965181  3.94746698  4.44984651  0.23878032  0.49978415  3.40173701\n",
      "  1.78804187 -3.71162348  2.52658573  3.51733965 -4.21154543]\n",
      "('error=', 3.8990875440355912e-07)\n"
     ]
    }
   ],
   "source": [
    "# c :BFGS\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def least_sq_reg(beta_ls, X, Y):\n",
    "    beta_ls=np.matrix(beta_ls)\n",
    "    z=Y-X*np.transpose(beta_ls)\n",
    "    return np.dot(np.transpose(z),z) #sum of the square errors, value of the obj function\n",
    "\n",
    "beta_ls0 = np.zeros(nvariables+1) #we need to initiate our initial point\n",
    "time_start = time.clock()\n",
    "res = minimize(least_sq_reg, beta_ls0, args=(X,Y), method = 'BFGS', options = {'disp': True}) #arguments for the model are X and Y\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print('time elapsed=',time_elapsed)\n",
    "print (res.x) \n",
    "print('error=',np.linalg.norm(np.transpose(beta_ls_exact)-res.x,ord=2)/np.linalg.norm(np.transpose(beta_ls_exact),ord=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: [[ 80069.17198142]]\n",
      "            Iterations: 69\n",
      "            Function evaluations: 7376\n",
      "            Gradient evaluations: 69\n",
      "('time elapsed=', 0.44362244810326956)\n",
      "[ 2.529688    2.42611795 -0.41628274 -1.40732997  2.17452321  0.18097296\n",
      " -0.86566037  1.82733167  0.89545756 -2.37274109 -2.98026287  0.86921388\n",
      " -2.12799598 -1.33736559  3.96339104  0.39167046  4.90936054 -1.49930577\n",
      " -2.20650607 -2.45209934  4.54480494 -2.50945927  3.44277718  0.4017845\n",
      " -4.20755144  4.73536521  3.16546231 -3.38488517  0.40808322 -1.50594605\n",
      "  0.90522338 -2.54797421  4.62549362  3.52351576 -0.37560542 -4.9888371\n",
      " -3.08694956  3.425699    3.9163188   2.99466534  2.38400526  4.09106594\n",
      "  0.98064769 -2.74332967  1.54621079  2.5743337  -0.24872238 -3.87753292\n",
      "  0.81225753 -1.5228928  -1.01981257  3.44046426  1.17337865 -1.47481359\n",
      "  1.96319445  1.13022121 -0.79221627  3.49593262 -4.58587543  3.64190782\n",
      " -4.52280165 -1.31603523 -2.94845595 -0.95580235 -2.70603471 -0.93610227\n",
      " -3.94137267 -2.11536268  2.76070039 -0.36996089 -3.79840963  3.25193477\n",
      " -0.21219763  3.8882679   3.4034158  -3.28101988  3.97913208 -1.11942642\n",
      " -0.09238251  3.9386026  -0.30191831 -3.04076529  0.66603468 -0.18145948\n",
      "  2.59631642 -1.19746224  1.94100323 -1.19947098 -3.46219287  4.13256111\n",
      " -2.61958812  3.94738555  4.44982851  0.23877718  0.49975691  3.40176514\n",
      "  1.78804415 -3.71163657  2.52658639  3.5173702  -4.21154472]\n",
      "('error=', 2.2592421341966809e-05)\n"
     ]
    }
   ],
   "source": [
    "# c :SLSQP\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def least_sq_reg(beta_ls, X, Y):\n",
    "    beta_ls=np.matrix(beta_ls)\n",
    "    z=Y-X*np.transpose(beta_ls)\n",
    "    return np.dot(np.transpose(z),z) #sum of the square errors, value of the obj function\n",
    "\n",
    "beta_ls0 = np.zeros(nvariables+1) #we need to initiate our initial point\n",
    "time_start = time.clock()\n",
    "res = minimize(least_sq_reg, beta_ls0, args=(X,Y), method = 'SLSQP', options = {'disp': True}) #arguments for the model are X and Y\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print('time elapsed=',time_elapsed)\n",
    "print (res.x) \n",
    "print('error=',np.linalg.norm(np.transpose(beta_ls_exact)-res.x,ord=2)/np.linalg.norm(np.transpose(beta_ls_exact),ord=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 80069.171181\n",
      "         Iterations: 202\n",
      "         Function evaluations: 526\n",
      "         Gradient evaluations: 514\n",
      "('time elapsed=', 0.10616097607999109)\n",
      "[ 2.52937819  2.42614537 -0.416329   -1.40731747  2.17453981  0.18095622\n",
      " -0.86562976  1.82734152  0.89547595 -2.37275002 -2.98026279  0.8691962\n",
      " -2.12799268 -1.33734636  3.96333928  0.39168133  4.90935173 -1.49929801\n",
      " -2.20653862 -2.45213626  4.54474815 -2.50949559  3.44278617  0.40178923\n",
      " -4.20757945  4.73542192  3.16544979 -3.38493149  0.40812153 -1.50592435\n",
      "  0.90518777 -2.54795406  4.62552082  3.52342293 -0.37562251 -4.98891794\n",
      " -3.08688004  3.42573093  3.91629732  2.99467597  2.3839587   4.09115999\n",
      "  0.98061908 -2.7432944   1.54618677  2.57436187 -0.24874123 -3.87750204\n",
      "  0.81225939 -1.52292386 -1.01978884  3.44045272  1.17340995 -1.47481519\n",
      "  1.96312049  1.13022595 -0.79217785  3.49589968 -4.58586759  3.6419209\n",
      " -4.52272037 -1.31598116 -2.94847069 -0.95579534 -2.7060463  -0.93610922\n",
      " -3.94129579 -2.11541699  2.76068832 -0.3699645  -3.79846781  3.25200259\n",
      " -0.21219711  3.88830245  3.40341196 -3.28097681  3.97907459 -1.11942657\n",
      " -0.09232724  3.93859128 -0.30193464 -3.04075866  0.66607113 -0.18141938\n",
      "  2.59631221 -1.19741161  1.94104044 -1.19952117 -3.4622064   4.1325098\n",
      " -2.61965214  3.94746652  4.44984593  0.23877983  0.49978384  3.40173677\n",
      "  1.78804155 -3.7116239   2.52658532  3.51733931 -4.21154594]\n",
      "('error=', 6.947613030647097e-06)\n"
     ]
    }
   ],
   "source": [
    "# c : CG\n",
    "\n",
    "def least_sq_reg_der(beta_ls,X,Y):\n",
    "    beta_ls=np.matrix(beta_ls)\n",
    "    pp=-2*np.dot(np.transpose(Y-np.dot(X,np.transpose(beta_ls))),X)\n",
    "    return np.squeeze(np.asarray(pp))\n",
    "        \n",
    "        \n",
    "def least_sq_reg_hess(beta_ls,X,Y):\n",
    "    return 2*np.dot(np.transpose(X),X)\n",
    "\n",
    "\n",
    "\n",
    "time_start = time.clock()\n",
    "#run your code\n",
    "                   \n",
    "res = minimize(least_sq_reg, beta_ls0, args=(X,Y), method = 'CG',jac=least_sq_reg_der, hess=least_sq_reg_hess, options = {'disp': True})\n",
    "time_elapsed = (time.clock() - time_start) \n",
    "print('time elapsed=',time_elapsed)\n",
    "print(res.x)\n",
    "np.linalg.inv(least_sq_reg_hess(res.x,X,Y))\n",
    "print('error=',np.linalg.norm(np.transpose(beta_ls_exact)-res.x,ord=2)/np.linalg.norm(np.transpose(beta_ls_exact),ord=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('time elapsed=', 1.6146098222234286)\n",
      "[ 1.34815496  0.47756379  0.63043872 -1.34886294  1.12344651  1.04690569\n",
      "  1.07372316  0.95661121  1.31605102  0.95386434  0.95333823  0.69837543\n",
      "  0.98819449  0.34129671  2.21643765  1.06664631  2.64677255  0.44140418\n",
      "  0.5431325   0.18055772  2.54372145  0.01848592  2.53950351  1.71502238\n",
      " -0.39659643  1.74490313  1.55172608 -1.10017101  0.88791668 -0.34086246\n",
      "  0.92257862 -1.43950674  0.8148101   1.36311721 -0.07739261 -1.00650106\n",
      " -0.58005414 -0.23059188  0.49831057  0.77157136  1.04438582  0.95009683\n",
      " -0.40022328 -0.05278119  0.41184307  0.53997451  0.90977278 -0.92095567\n",
      " -0.21444047  0.62336529 -0.55493285  0.88743095 -0.51135637  0.1360919\n",
      "  0.46035737  0.43666156  0.42262037  0.59947066 -0.55550073  0.41787204\n",
      " -1.38154099 -0.23727933 -0.97614738  0.01417302 -1.21297736 -0.01925373\n",
      " -1.17015599  0.38207876  0.57973876 -0.22721596 -0.7550735  -0.07090566\n",
      "  0.69169383  0.38120511  0.28981997 -1.5746251   0.3747195  -0.50498812\n",
      " -0.04605738  0.45537587 -0.25693813 -1.07213524 -0.83681257  0.27696885\n",
      "  0.07420894 -0.14833706  0.01031502 -0.67037339 -1.47780015 -0.07227105\n",
      " -0.78438627  0.13553309  0.86497498  0.66966845  0.0449279   0.99541675\n",
      "  0.25801495 -0.74740408  0.93056603  1.32373149 -0.57406987]\n",
      "('error=', 0.8159236852678442)\n"
     ]
    }
   ],
   "source": [
    "# c : COBYLA\n",
    "\n",
    "def least_sq_reg_der(beta_ls,X,Y):\n",
    "    beta_ls=np.matrix(beta_ls)\n",
    "    pp=-2*np.dot(np.transpose(Y-np.dot(X,np.transpose(beta_ls))),X)\n",
    "    return np.squeeze(np.asarray(pp))\n",
    "        \n",
    "        \n",
    "def least_sq_reg_hess(beta_ls,X,Y):\n",
    "    return 2*np.dot(np.transpose(X),X)\n",
    "\n",
    "\n",
    "\n",
    "time_start = time.clock()\n",
    "#run your code\n",
    "                   \n",
    "res = minimize(least_sq_reg, beta_ls0, args=(X,Y), method = 'COBYLA',jac=least_sq_reg_der, hess=least_sq_reg_hess, options = {'disp': True})\n",
    "time_elapsed = (time.clock() - time_start) \n",
    "print('time elapsed=',time_elapsed)\n",
    "print(res.x)\n",
    "np.linalg.inv(least_sq_reg_hess(res.x,X,Y))\n",
    "print('error=',np.linalg.norm(np.transpose(beta_ls_exact)-res.x,ord=2)/np.linalg.norm(np.transpose(beta_ls_exact),ord=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D)\n",
    "Considering again the least squares estimation problem, estimate the value of the regression coefficients\n",
    "by implementing the:\n",
    "\n",
    "i. Gradient method\n",
    "\n",
    "ii. Newton method\n",
    "\n",
    "iii. Quasi-Newton method\n",
    "\n",
    "Consider a like search technique to improve the algorithm convergence, e.x., Armijo rule. Compare the\n",
    "performance of these algorithms (iterations, function, gradient and hessian evaluations as well as total\n",
    "computational time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#definitinition of OF #objective function\n",
    "def least_sq_reg(beta_ls, X, Y):\n",
    "    beta_ls=np.matrix(beta_ls)\n",
    "    z=Y-X*np.transpose(beta_ls)\n",
    "    return np.transpose(z)*z\n",
    "\n",
    "#definition of Gradient\n",
    "def least_sq_reg_der(beta_ls,X,Y):\n",
    "    beta_ls=np.matrix(beta_ls)\n",
    "    pp=-2*np.transpose(Y-X*np.transpose(beta_ls))*X\n",
    "    aa= np.squeeze(np.asarray(pp))\n",
    "    return aa\n",
    "\n",
    "#definition of hessian\n",
    "def least_sq_reg_hess(beta_ls,X,Y):\n",
    "    ss=2*np.dot(np.transpose(X),X)\n",
    "    return ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient method\n",
    "\n",
    " $\\rightarrow$ From an initial iterate $x_0$\n",
    "\n",
    "$\\rightarrow$ Compute search (descent) directions $p_k$\n",
    "\n",
    "$\\rightarrow$ Far from the solution, compute a steplength $\\alpha_k>0$\n",
    "\n",
    "$\\rightarrow$ Movement:\n",
    "$$x_{k+1} = x_k + \\alpha_k\\ p_k$$\n",
    "Until convergence to a local solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('time elapsed=', 20.377335144672543)\n",
      "('iterations', 99999)\n",
      "4453518.4028\n",
      "[ 0.05282976  0.64113981  0.07209548  0.04871036  0.43447612  0.16998291\n",
      "  0.109676    0.70771936  0.33319051  0.00233326 -0.26011946  0.29555244\n",
      "  0.06487088  0.0818291   0.70434035  0.44122414  0.68690641 -0.11269109\n",
      " -0.16002377 -0.08491781  0.87603946 -0.18475172  0.63171682  0.26130579\n",
      " -0.57336813  0.94909169  0.61983924 -0.33247985  0.31993902 -0.00964228\n",
      "  0.51786303 -0.37165651  0.71446156  0.9968811   0.18255093 -0.64136729\n",
      " -0.10293328  0.7849801   0.88457105  0.57576728  0.56615348  0.85068567\n",
      "  0.32213325 -0.01408248  0.55557692  0.65794985  0.40269202 -0.26370334\n",
      "  0.39563088 -0.00946688  0.13986133  0.65418044  0.29889514 -0.01626181\n",
      "  0.61194155  0.2427539   0.21023681  0.9901915  -0.35360858  0.90587343\n",
      " -0.51649615  0.02321486 -0.32545866 -0.00497301 -0.54980912  0.02779685\n",
      " -0.35852151 -0.01666443  0.72364021  0.38795701 -0.43488529  0.71334236\n",
      "  0.20035609  0.93571903  0.50846396 -0.55895823  0.83883684 -0.14150831\n",
      "  0.15395954  0.78299874  0.0853416  -0.17913807  0.31256484  0.22815309\n",
      "  0.71183615  0.01066598  0.60959844  0.29076584 -0.42890454  0.86246375\n",
      " -0.16594802  0.88592694  0.90976724  0.25615151  0.59117237  0.60236587\n",
      "  0.53313102 -0.31037481  0.61900411  0.79566619 -0.3255901 ]\n",
      "[[ 2.52918633  2.4261458  -0.41632861 -1.40731707  2.17454027  0.18095673\n",
      "  -0.8656291   1.82734185  0.89547625 -2.37274953 -2.98026242  0.86919659\n",
      "  -2.1279922  -1.33734599  3.96333954  0.39168156  4.9093521  -1.49929783\n",
      "  -2.20653836 -2.45213602  4.54474868 -2.50949533  3.44278642  0.4017894\n",
      "  -4.20757911  4.73542248  3.1654502  -3.38493122  0.4081219  -1.50592405\n",
      "   0.9051882  -2.54795345  4.62552112  3.52342339 -0.37562193 -4.98891742\n",
      "  -3.08687985  3.42573122  3.91629759  2.99467649  2.38395894  4.09116047\n",
      "   0.98061963 -2.74329385  1.54618723  2.57436218 -0.24874098 -3.87750166\n",
      "   0.8122598  -1.52292344 -1.01978842  3.44045309  1.17341041 -1.47481477\n",
      "   1.96312074  1.1302264  -0.79217751  3.49589995 -4.58586708  3.64192144\n",
      "  -4.52271995 -1.31598101 -2.94847046 -0.95579506 -2.70604594 -0.93610869\n",
      "  -3.94129544 -2.11541672  2.76068874 -0.36996398 -3.79846746  3.25200279\n",
      "  -0.21219685  3.88830281  3.40341224 -3.28097658  3.97907492 -1.11942621\n",
      "  -0.09232704  3.93859144 -0.30193412 -3.04075808  0.66607163 -0.18141882\n",
      "   2.59631264 -1.19741144  1.94104059 -1.19952069 -3.46220583  4.13251021\n",
      "  -2.6196518   3.947467    4.44984655  0.23878037  0.49978419  3.40173709\n",
      "   1.78804194 -3.71162344  2.52658577  3.5173397  -4.21154545]]\n",
      "('Tolerance=', 394792.46412593417)\n",
      "('error=', 4.5731469414991475)\n"
     ]
    }
   ],
   "source": [
    "### d -- i) Gradient method (Without Armijo Rule)\n",
    "\n",
    "(a,b)=X.shape\n",
    "beta_lsg=np.zeros(b) #initial value for beta\n",
    "alpha= 0.0000000001  ###0.00005\n",
    "n_iter=100000 #maximim nunber iteration\n",
    "OF_iter=np.zeros(n_iter)\n",
    "tol_iter=np.zeros(n_iter)\n",
    "alpha_iter=np.zeros(n_iter)\n",
    "i=0;\n",
    "tol=1000; # Tolerance\n",
    "epsilon=1e-3;\n",
    "\n",
    "time_start = time.clock()\n",
    "while (i <= n_iter-2) and (tol>epsilon):\n",
    "    i=i+1\n",
    "    grad=least_sq_reg_der(beta_lsg,X,Y) #this function gives us the value of the gradient\n",
    "    ddirect=-grad\n",
    "    beta_lsg=beta_lsg+alpha*ddirect\n",
    "    OF_iter[i]=least_sq_reg(beta_lsg,X,Y) # Objective Function ---Residuals\n",
    "    tol=np.linalg.norm(grad,ord=2)\n",
    "    tol_iter[i]=tol\n",
    "    \n",
    "time_elapsed = (time.clock() - time_start) \n",
    "print('time elapsed=',time_elapsed)\n",
    "print('iterations',i)\n",
    "print(OF_iter[i])\n",
    "print(beta_lsg)\n",
    "print(np.transpose(beta_ls_exact))\n",
    "print('Tolerance=',tol)\n",
    "print('error=',np.linalg.norm(np.transpose(beta_ls_exact)-beta_lsg,ord=2)/np.linalg.norm(beta_lsg,ord=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('time elapsed=', 271.0848733142484)\n",
      "('iterations', 99999)\n",
      "80076.4996823\n",
      "[ 0.97062722  2.42989237 -0.41282035 -1.40393962  2.17807329  0.18434977\n",
      " -0.86085376  1.83033545  0.8982917  -2.36862531 -2.97669944  0.87246582\n",
      " -2.12468981 -1.33412007  3.96579982  0.39298093  4.912143   -1.49744956\n",
      " -2.20429914 -2.45065464  4.54873515 -2.50711496  3.44460127  0.40374573\n",
      " -4.20523187  4.73909215  3.16826084 -3.38247018  0.41106524 -1.50319254\n",
      "  0.90883194 -2.54341521  4.62839072  3.52715335 -0.37113347 -4.98457512\n",
      " -3.08521132  3.42728466  3.91849479  2.99855987  2.38602586  4.09491209\n",
      "  0.98479434 -2.73941463  1.55044791  2.57720371 -0.24701874 -3.8742213\n",
      "  0.81568384 -1.51917194 -1.0162858   3.44349569  1.17706418 -1.47069424\n",
      "  1.96529481  1.1335256  -0.78931818  3.49808478 -4.58218159  3.64633623\n",
      " -4.51938499 -1.3140877  -2.94684629 -0.95358758 -2.70309932 -0.93194975\n",
      " -3.93828432 -2.11337858  2.76366811 -0.3659416  -3.79594539  3.25401784\n",
      " -0.2100264   3.89181865  3.40602041 -3.27904239  3.98186244 -1.11703655\n",
      " -0.09046106  3.94004846 -0.2973229  -3.03605121  0.67014647 -0.17682752\n",
      "  2.59968721 -1.19587458  1.94212448 -1.19526725 -3.45796015  4.13527282\n",
      " -2.61693636  3.95111825  4.45481395  0.24320434  0.50293947  3.40448567\n",
      "  1.79146009 -3.70707192  2.53058943  3.52046158 -4.20783084]\n",
      "[[ 2.52918633  2.4261458  -0.41632861 -1.40731707  2.17454027  0.18095673\n",
      "  -0.8656291   1.82734185  0.89547625 -2.37274953 -2.98026242  0.86919659\n",
      "  -2.1279922  -1.33734599  3.96333954  0.39168156  4.9093521  -1.49929783\n",
      "  -2.20653836 -2.45213602  4.54474868 -2.50949533  3.44278642  0.4017894\n",
      "  -4.20757911  4.73542248  3.1654502  -3.38493122  0.4081219  -1.50592405\n",
      "   0.9051882  -2.54795345  4.62552112  3.52342339 -0.37562193 -4.98891742\n",
      "  -3.08687985  3.42573122  3.91629759  2.99467649  2.38395894  4.09116047\n",
      "   0.98061963 -2.74329385  1.54618723  2.57436218 -0.24874098 -3.87750166\n",
      "   0.8122598  -1.52292344 -1.01978842  3.44045309  1.17341041 -1.47481477\n",
      "   1.96312074  1.1302264  -0.79217751  3.49589995 -4.58586708  3.64192144\n",
      "  -4.52271995 -1.31598101 -2.94847046 -0.95579506 -2.70604594 -0.93610869\n",
      "  -3.94129544 -2.11541672  2.76068874 -0.36996398 -3.79846746  3.25200279\n",
      "  -0.21219685  3.88830281  3.40341224 -3.28097658  3.97907492 -1.11942621\n",
      "  -0.09232704  3.93859144 -0.30193412 -3.04075808  0.66607163 -0.18141882\n",
      "   2.59631264 -1.19741144  1.94104059 -1.19952069 -3.46220583  4.13251021\n",
      "  -2.6196518   3.947467    4.44984655  0.23878037  0.49978419  3.40173709\n",
      "   1.78804194 -3.71162344  2.52658577  3.5173397  -4.21154545]]\n",
      "('Tolerance=', 33.966473832271888)\n",
      "('error=', 0.056635881780326823)\n"
     ]
    }
   ],
   "source": [
    "### d -- i) Gradient method (With Armijo Rule)\n",
    "\n",
    "(a,b)=X.shape\n",
    "beta_lsg=np.zeros(b) #initial value for beta\n",
    "alpha= 0.0000000001  ###0.00005\n",
    "n_iter=100000 #maximim nunber iteration\n",
    "OF_iter=np.zeros(n_iter)\n",
    "tol_iter=np.zeros(n_iter)\n",
    "alpha_iter=np.zeros(n_iter)\n",
    "i=0;\n",
    "tol=1000; # Tolerance\n",
    "epsilon=1e-3;\n",
    "\n",
    "time_start = time.clock()\n",
    "while (i <= n_iter-2) and (tol>epsilon):\n",
    "    i=i+1\n",
    "    grad=least_sq_reg_der(beta_lsg,X,Y) #this function gives us the value of the gradient\n",
    "    ddirect=-grad\n",
    "    ########################\n",
    "    #     Armijo Rule\n",
    "    sigma=0.1\n",
    "    beta=0.5\n",
    "    alpha=1\n",
    "    while (least_sq_reg(beta_lsg+alpha*ddirect,X,Y)> least_sq_reg(beta_lsg,X,Y)+alpha*sigma*np.dot(grad,ddirect)):\n",
    "        alpha=alpha*beta\n",
    "    ########################\n",
    "    beta_lsg=beta_lsg+alpha*ddirect\n",
    "    OF_iter[i]=least_sq_reg(beta_lsg,X,Y) # Objective Function ---Residuals\n",
    "    tol=np.linalg.norm(grad,ord=2)\n",
    "    tol_iter[i]=tol\n",
    "    \n",
    "time_elapsed = (time.clock() - time_start) \n",
    "print('time elapsed=',time_elapsed)\n",
    "print('iterations',i)\n",
    "print(OF_iter[i])\n",
    "print(beta_lsg)\n",
    "print(np.transpose(beta_ls_exact))\n",
    "print('Tolerance=',tol)\n",
    "print('error=',np.linalg.norm(np.transpose(beta_ls_exact)-beta_lsg,ord=2)/np.linalg.norm(beta_lsg,ord=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newtons method\n",
    "\n",
    " $\\rightarrow$ From an initial iterate $x_0$\n",
    "\n",
    "$\\rightarrow$ Compute search (descent) directions $p_k=-(\\nabla^2 f(x_k))^{-1} \\nabla f(x_k)$, whenever $\\nabla^2 f(x_k)$ is\n",
    "nonsingular. \n",
    "\n",
    "$\\rightarrow$ Far from the solution, compute a steplength $\\alpha_k>0$\n",
    "\n",
    "$\\rightarrow$ Movement:\n",
    "$$x_{k+1} = x_k + \\alpha_k\\ p_k$$\n",
    "Until convergence to a local solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('time elapsed=', 234.86125793171232)\n",
      "('iterations', 99999)\n",
      "81158.1437743\n",
      "[ 2.51214608  2.40979979 -0.41352362 -1.39783536  2.15988943  0.17973754\n",
      " -0.85979697  1.81503024  0.88944303 -2.35676327 -2.96018308  0.86334043\n",
      " -2.11365497 -1.3283357   3.93663677  0.38904263  4.87627563 -1.48919639\n",
      " -2.19167193 -2.4356149   4.5141287  -2.49258775  3.41959085  0.39908237\n",
      " -4.17923079  4.70351785  3.14412317 -3.36212545  0.4053722  -1.49577797\n",
      "  0.89908955 -2.53078677  4.59435694  3.49968453 -0.3730912  -4.95530488\n",
      " -3.06608218  3.40265055  3.88991176  2.97450003  2.36789716  4.06359651\n",
      "  0.97401276 -2.72481106  1.53576989  2.55701757 -0.2470651  -3.85137722\n",
      "  0.80678724 -1.51266283 -1.01291765  3.41727324  1.16550463 -1.4648783\n",
      "  1.94989433  1.12261157 -0.78684026  3.47234653 -4.55497007  3.61738421\n",
      " -4.49224838 -1.30711466 -2.92860532 -0.94935545 -2.68781411 -0.92980172\n",
      " -3.91474119 -2.10116422  2.74208876 -0.36747137 -3.7728755   3.23009262\n",
      " -0.21076719  3.8621056   3.38048195 -3.2588712   3.95226613 -1.11188415\n",
      " -0.09170499  3.91205541 -0.29989986 -3.02027115  0.66158401 -0.18019652\n",
      "  2.57882013 -1.18934395  1.92796294 -1.19143899 -3.43887942  4.10466766\n",
      " -2.60200205  3.92087117  4.41986596  0.2371716   0.49641692  3.37881808\n",
      "  1.77599511 -3.68661659  2.50956305  3.49364183 -4.18317041]\n",
      "[[ 2.52918633  2.4261458  -0.41632861 -1.40731707  2.17454027  0.18095673\n",
      "  -0.8656291   1.82734185  0.89547625 -2.37274953 -2.98026242  0.86919659\n",
      "  -2.1279922  -1.33734599  3.96333954  0.39168156  4.9093521  -1.49929783\n",
      "  -2.20653836 -2.45213602  4.54474868 -2.50949533  3.44278642  0.4017894\n",
      "  -4.20757911  4.73542248  3.1654502  -3.38493122  0.4081219  -1.50592405\n",
      "   0.9051882  -2.54795345  4.62552112  3.52342339 -0.37562193 -4.98891742\n",
      "  -3.08687985  3.42573122  3.91629759  2.99467649  2.38395894  4.09116047\n",
      "   0.98061963 -2.74329385  1.54618723  2.57436218 -0.24874098 -3.87750166\n",
      "   0.8122598  -1.52292344 -1.01978842  3.44045309  1.17341041 -1.47481477\n",
      "   1.96312074  1.1302264  -0.79217751  3.49589995 -4.58586708  3.64192144\n",
      "  -4.52271995 -1.31598101 -2.94847046 -0.95579506 -2.70604594 -0.93610869\n",
      "  -3.94129544 -2.11541672  2.76068874 -0.36996398 -3.79846746  3.25200279\n",
      "  -0.21219685  3.88830281  3.40341224 -3.28097658  3.97907492 -1.11942621\n",
      "  -0.09232704  3.93859144 -0.30193412 -3.04075808  0.66607163 -0.18141882\n",
      "   2.59631264 -1.19741144  1.94104059 -1.19952069 -3.46220583  4.13251021\n",
      "  -2.6196518   3.947467    4.44984655  0.23878037  0.49978419  3.40173709\n",
      "   1.78804194 -3.71162344  2.52658577  3.5173397  -4.21154545]]\n",
      "('Tolerance=', 5010755.7621989259)\n",
      "('error=', 0.0067831426802369759)\n"
     ]
    }
   ],
   "source": [
    "# d-- ii) Newton method (Without Armijo Rule)\n",
    "\n",
    "\n",
    "(a,b)=X.shape\n",
    "beta_lsg=np.zeros(b) #initial value for beta\n",
    "alpha= 0.00005\n",
    "n_iter=100000 #maximim nunber iteration\n",
    "OF_iter=np.zeros(n_iter)\n",
    "tol_iter=np.zeros(n_iter)\n",
    "alpha_iter=np.zeros(n_iter)\n",
    "i=0;\n",
    "tol=1000; # Tolerance\n",
    "epsilon=1e-3;\n",
    "\n",
    "time_start = time.clock()\n",
    "while (i <= n_iter-2) and (tol>epsilon):\n",
    "    i=i+1\n",
    "    grad=least_sq_reg_der(beta_lsg,X,Y)\n",
    "    hess=least_sq_reg_hess(beta_lsg,X,Y) #this function gives us the value of the hessian\n",
    "    ddirect=-(np.dot(np.linalg.inv(hess), grad))\n",
    "    beta_lsg=beta_lsg+alpha*ddirect\n",
    "    OF_iter[i]=least_sq_reg(beta_lsg,X,Y) \n",
    "    tol=np.linalg.norm(hess,ord=2)\n",
    "    tol_iter[i]=tol\n",
    "    \n",
    "time_elapsed = (time.clock() - time_start) \n",
    "print('time elapsed=',time_elapsed)\n",
    "print('iterations',i)\n",
    "print(OF_iter[i])\n",
    "print(beta_lsg)\n",
    "print(np.transpose(beta_ls_exact))\n",
    "print('Tolerance=',tol)\n",
    "print('error=',np.linalg.norm(np.transpose(beta_ls_exact)-beta_lsg,ord=2)/np.linalg.norm(beta_lsg,ord=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('time elapsed=', 359.512197962933)\n",
      "('iterations', 99999)\n",
      "80069.1711811\n",
      "[ 2.52918633  2.4261458  -0.41632861 -1.40731707  2.17454027  0.18095673\n",
      " -0.8656291   1.82734185  0.89547625 -2.37274953 -2.98026242  0.86919659\n",
      " -2.1279922  -1.33734599  3.96333954  0.39168156  4.9093521  -1.49929783\n",
      " -2.20653836 -2.45213602  4.54474868 -2.50949533  3.44278642  0.4017894\n",
      " -4.20757911  4.73542248  3.1654502  -3.38493122  0.4081219  -1.50592405\n",
      "  0.9051882  -2.54795345  4.62552112  3.52342339 -0.37562193 -4.98891742\n",
      " -3.08687985  3.42573122  3.91629759  2.99467649  2.38395894  4.09116047\n",
      "  0.98061963 -2.74329385  1.54618723  2.57436218 -0.24874098 -3.87750166\n",
      "  0.8122598  -1.52292344 -1.01978842  3.44045309  1.17341041 -1.47481477\n",
      "  1.96312074  1.1302264  -0.79217751  3.49589995 -4.58586708  3.64192144\n",
      " -4.52271995 -1.31598101 -2.94847046 -0.95579506 -2.70604594 -0.93610869\n",
      " -3.94129544 -2.11541672  2.76068874 -0.36996398 -3.79846746  3.25200279\n",
      " -0.21219685  3.88830281  3.40341224 -3.28097658  3.97907492 -1.11942621\n",
      " -0.09232704  3.93859144 -0.30193412 -3.04075808  0.66607163 -0.18141882\n",
      "  2.59631264 -1.19741144  1.94104059 -1.19952069 -3.46220583  4.13251021\n",
      " -2.6196518   3.947467    4.44984655  0.23878037  0.49978419  3.40173709\n",
      "  1.78804194 -3.71162344  2.52658577  3.5173397  -4.21154545]\n",
      "[[ 2.52918633  2.4261458  -0.41632861 -1.40731707  2.17454027  0.18095673\n",
      "  -0.8656291   1.82734185  0.89547625 -2.37274953 -2.98026242  0.86919659\n",
      "  -2.1279922  -1.33734599  3.96333954  0.39168156  4.9093521  -1.49929783\n",
      "  -2.20653836 -2.45213602  4.54474868 -2.50949533  3.44278642  0.4017894\n",
      "  -4.20757911  4.73542248  3.1654502  -3.38493122  0.4081219  -1.50592405\n",
      "   0.9051882  -2.54795345  4.62552112  3.52342339 -0.37562193 -4.98891742\n",
      "  -3.08687985  3.42573122  3.91629759  2.99467649  2.38395894  4.09116047\n",
      "   0.98061963 -2.74329385  1.54618723  2.57436218 -0.24874098 -3.87750166\n",
      "   0.8122598  -1.52292344 -1.01978842  3.44045309  1.17341041 -1.47481477\n",
      "   1.96312074  1.1302264  -0.79217751  3.49589995 -4.58586708  3.64192144\n",
      "  -4.52271995 -1.31598101 -2.94847046 -0.95579506 -2.70604594 -0.93610869\n",
      "  -3.94129544 -2.11541672  2.76068874 -0.36996398 -3.79846746  3.25200279\n",
      "  -0.21219685  3.88830281  3.40341224 -3.28097658  3.97907492 -1.11942621\n",
      "  -0.09232704  3.93859144 -0.30193412 -3.04075808  0.66607163 -0.18141882\n",
      "   2.59631264 -1.19741144  1.94104059 -1.19952069 -3.46220583  4.13251021\n",
      "  -2.6196518   3.947467    4.44984655  0.23878037  0.49978419  3.40173709\n",
      "   1.78804194 -3.71162344  2.52658577  3.5173397  -4.21154545]]\n",
      "('Tolerance=', 5010755.7621989259)\n",
      "('error=', 1.7121698297293485e-12)\n"
     ]
    }
   ],
   "source": [
    "# d-- ii) Newton method (With Armijo Rule)\n",
    "\n",
    "\n",
    "(a,b)=X.shape\n",
    "beta_lsg=np.zeros(b) #initial value for beta\n",
    "alpha= 0.00005\n",
    "n_iter=100000 #maximim nunber iteration\n",
    "OF_iter=np.zeros(n_iter)\n",
    "tol_iter=np.zeros(n_iter)\n",
    "alpha_iter=np.zeros(n_iter)\n",
    "i=0;\n",
    "tol=1000; # Tolerance\n",
    "epsilon=1e-3;\n",
    "\n",
    "time_start = time.clock()\n",
    "while (i <= n_iter-2) and (tol>epsilon):\n",
    "    i=i+1\n",
    "    grad=least_sq_reg_der(beta_lsg,X,Y)\n",
    "    hess=least_sq_reg_hess(beta_lsg,X,Y) #this function gives us the value of the hessian\n",
    "    ddirect=-(np.dot(np.linalg.inv(hess), grad))\n",
    "    ########################\n",
    "    #     Armijo Rule\n",
    "    sigma=0.1\n",
    "    beta=0.5\n",
    "    alpha=1\n",
    "    while (least_sq_reg(beta_lsg+alpha*ddirect,X,Y)> least_sq_reg(beta_lsg,X,Y)+alpha*sigma*np.dot(grad,ddirect)):\n",
    "        alpha=alpha*beta\n",
    "    ########################\n",
    "    beta_lsg=beta_lsg+alpha*ddirect\n",
    "    OF_iter[i]=least_sq_reg(beta_lsg,X,Y) \n",
    "    tol=np.linalg.norm(hess,ord=2)\n",
    "    tol_iter[i]=tol\n",
    "    \n",
    "time_elapsed = (time.clock() - time_start) \n",
    "print('time elapsed=',time_elapsed)\n",
    "print('iterations',i)\n",
    "print(OF_iter[i])\n",
    "print(beta_lsg)\n",
    "print(np.transpose(beta_ls_exact))\n",
    "print('Tolerance=',tol)\n",
    "print('error=',np.linalg.norm(np.transpose(beta_ls_exact)-beta_lsg,ord=2)/np.linalg.norm(beta_lsg,ord=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# d -- iii) Quasi-Newton method\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## E)\n",
    "Estimate the value of the regression coefficients y implementing the coordinate gradient method and\n",
    "the stochastic gradient method. Compare their performance with the algorithms in c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
